<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Redis Makefile注解]]></title>
    <url>%2F2019%2F04%2F26%2F2019-04-26-Redis-Makefile%E6%B3%A8%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[Redis Makefile注解Redis的makefile是阅读源码的第一步，总共有292行，读起来也是头大，记录之。 4.02版本源码为： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321# Redis Makefile# Copyright (C) 2009 Salvatore Sanfilippo &lt;antirez at gmail dot com&gt;# This file is released under the BSD license, see the COPYING file## The Makefile composes the final FINAL_CFLAGS and FINAL_LDFLAGS using# what is needed for Redis plus the standard CFLAGS and LDFLAGS passed.# However when building the dependencies (Jemalloc, Lua, Hiredis, ...)# CFLAGS and LDFLAGS are propagated to the dependencies, so to pass# flags only to be used when compiling / linking Redis itself REDIS_CFLAGS# and REDIS_LDFLAGS are used instead (this is the case of 'make gcov').## Dependencies are stored in the Makefile.dep file. To rebuild this file# Just use 'make dep', but this is only needed by developers.release_hdr := $(shell sh -c './mkreleasehdr.sh')# uname -s 获取操作系统的类型 Linuxuname_S := $(shell sh -c 'uname -s 2&gt;/dev/null || echo not')#uname -m 获取机子的架构 x86_64uname_M := $(shell sh -c 'uname -m 2&gt;/dev/null || echo not')# 优化选项OPTIMIZATION?=-O2# 依赖目标DEPENDENCY_TARGETS=hiredis linenoise luaNODEPS:=clean distclean# Default settings# 使用c99标准编译，-pedantic 保证代码规范满足ISO C和ISO C++标准STD=-std=c99 -pedantic -DREDIS_STATIC=''# 输出所有编译警告信息 ，Wno-missing-field-initializers 不输出missing-的警告信息WARN=-Wall -W -Wno-missing-field-initializersOPT=$(OPTIMIZATION)#默认目录PREFIX?=/usr/local#安装的默认目录INSTALL_BIN=$(PREFIX)/binINSTALL=install# Default allocator defaults to Jemalloc if it's not an ARM#内存分配器的指定 默认libc，linux系统而且架构不是armv61和71的时候则是jemalloc，MALLOC=libcifneq ($(uname_M),armv6l)ifneq ($(uname_M),armv7l)ifeq ($(uname_S),Linux) MALLOC=jemallocendifendifendif# To get ARM stack traces if Redis crashes we need a special C flag.ifneq (,$(findstring armv,$(uname_M))) CFLAGS+=-funwind-tablesendif# Backwards compatibility for selecting an allocator#编译的时候指定内存分配器ifeq ($(USE_TCMALLOC),yes) MALLOC=tcmallocendififeq ($(USE_TCMALLOC_MINIMAL),yes) MALLOC=tcmalloc_minimalendififeq ($(USE_JEMALLOC),yes) MALLOC=jemallocendififeq ($(USE_JEMALLOC),no) MALLOC=libcendif# Override default settings if possible-include .make-settings# 最终的编译选项CFLAGS是-c的选项，LDFLAGS是链接的选项FINAL_CFLAGS=$(STD) $(WARN) $(OPT) $(DEBUG) $(CFLAGS) $(REDIS_CFLAGS)FINAL_LDFLAGS=$(LDFLAGS) $(REDIS_LDFLAGS) $(DEBUG)# m这个lib是libmath 也就是math的链接FINAL_LIBS=-lm# 调试信息DEBUG=-g -ggdb#根据操作系统继续指定编译选项ifeq ($(uname_S),SunOS) # SunOS ifneq ($(@@),32bit) CFLAGS+= -m64 LDFLAGS+= -m64 endif DEBUG=-g DEBUG_FLAGS=-g export CFLAGS LDFLAGS DEBUG DEBUG_FLAGS INSTALL=cp -pf FINAL_CFLAGS+= -D__EXTENSIONS__ -D_XPG6 FINAL_LIBS+= -ldl -lnsl -lsocket -lresolv -lpthread -lrtelseifeq ($(uname_S),Darwin) # Darwin FINAL_LIBS+= -ldlelseifeq ($(uname_S),AIX) # AIX FINAL_LDFLAGS+= -Wl,-bexpall FINAL_LIBS+=-ldl -pthread -lcrypt -lbsdelseifeq ($(uname_S),OpenBSD) # OpenBSD FINAL_LIBS+= -lpthreadelseifeq ($(uname_S),FreeBSD) # FreeBSD FINAL_LIBS+= -lpthreadelse # 特别是对Linux的指定 # All the other OSes (notably Linux) # -rdynamic将链接器将所有符号添加到动态符号表 FINAL_LDFLAGS+= -rdynamic #pthread库 用于多线程， dl是libdl 动态链接库 FINAL_LIBS+=-ldl -pthreadendifendifendifendifendif# Include paths to dependencies# -I 指定头文件的目录FINAL_CFLAGS+= -I../deps/hiredis -I../deps/linenoise -I../deps/lua/srcifeq ($(MALLOC),tcmalloc) FINAL_CFLAGS+= -DUSE_TCMALLOC FINAL_LIBS+= -ltcmallocendififeq ($(MALLOC),tcmalloc_minimal) FINAL_CFLAGS+= -DUSE_TCMALLOC FINAL_LIBS+= -ltcmalloc_minimalendif#使用jemalloc的话 链接 libjemalloc.a -I指定jemalloc的头文件目录ifeq ($(MALLOC),jemalloc) DEPENDENCY_TARGETS+= jemalloc FINAL_CFLAGS+= -DUSE_JEMALLOC -I../deps/jemalloc/include FINAL_LIBS+= ../deps/jemalloc/lib/libjemalloc.aendif#redis 的gcc -c 选项REDIS_CC=$(QUIET_CC)$(CC) $(FINAL_CFLAGS)#redis的gcc 链接选项REDIS_LD=$(QUIET_LINK)$(CC) $(FINAL_LDFLAGS)#redis的安装选项REDIS_INSTALL=$(QUIET_INSTALL)$(INSTALL)CCCOLOR="\033[34m"LINKCOLOR="\033[34;1m"SRCCOLOR="\033[33m"BINCOLOR="\033[37;1m"MAKECOLOR="\033[32;1m"ENDCOLOR="\033[0m"ifndef VQUIET_CC = @printf ' %b %b\n' $(CCCOLOR)CC$(ENDCOLOR) $(SRCCOLOR)$@$(ENDCOLOR) 1&gt;&amp;2;QUIET_LINK = @printf ' %b %b\n' $(LINKCOLOR)LINK$(ENDCOLOR) $(BINCOLOR)$@$(ENDCOLOR) 1&gt;&amp;2;QUIET_INSTALL = @printf ' %b %b\n' $(LINKCOLOR)INSTALL$(ENDCOLOR) $(BINCOLOR)$@$(ENDCOLOR) 1&gt;&amp;2;endifREDIS_SERVER_NAME=redis-serverREDIS_SENTINEL_NAME=redis-sentinel# redis-server的需要使用的对象文件，也就是各个模块REDIS_SERVER_OBJ=adlist.o quicklist.o ae.o anet.o dict.o server.o sds.o zmalloc.o lzf_c.o lzf_d.o pqsort.o zipmap.o sha1.o ziplist.o release.o networking.o util.o object.o db.o replication.o rdb.o t_string.o t_list.o t_set.o t_zset.o t_hash.o config.o aof.o pubsub.o multi.o debug.o sort.o intset.o syncio.o cluster.o crc16.o endianconv.o slowlog.o scripting.o bio.o rio.o rand.o memtest.o crc64.o bitops.o sentinel.o notify.o setproctitle.o blocked.o hyperloglog.o latency.o sparkline.o redis-check-rdb.o redis-check-aof.o geo.o lazyfree.o module.o evict.o expire.o geohash.o geohash_helper.o childinfo.o defrag.o siphash.o rax.oREDIS_CLI_NAME=redis-cli#redis-cli 需要使用的对象文件REDIS_CLI_OBJ=anet.o adlist.o redis-cli.o zmalloc.o release.o anet.o ae.o crc64.oREDIS_BENCHMARK_NAME=redis-benchmark#redis-benchmark需要使用的对象文件REDIS_BENCHMARK_OBJ=ae.o anet.o redis-benchmark.o adlist.o zmalloc.o redis-benchmark.oREDIS_CHECK_RDB_NAME=redis-check-rdbREDIS_CHECK_AOF_NAME=redis-check-aof#所有需要需要构建的对象，第一条规则也就是默认规则，不指定规则的话，从第一个规则执行all: $(REDIS_SERVER_NAME) $(REDIS_SENTINEL_NAME) $(REDIS_CLI_NAME) $(REDIS_BENCHMARK_NAME) $(REDIS_CHECK_RDB_NAME) $(REDIS_CHECK_AOF_NAME) @echo "" @echo "Hint: It's a good idea to run 'make test' ;)" @echo ""#Makefil.dep 的生成Makefile.dep: -$(REDIS_CC) -MM *.c &gt; Makefile.dep 2&gt; /dev/null || trueifeq (0, $(words $(findstring $(MAKECMDGOALS), $(NODEPS))))-include Makefile.dependif.PHONY: all#先清除所有编译的输出然后， 将所有设置持久化persist-settings: distclean echo STD=$(STD) &gt;&gt; .make-settings echo WARN=$(WARN) &gt;&gt; .make-settings echo OPT=$(OPT) &gt;&gt; .make-settings echo MALLOC=$(MALLOC) &gt;&gt; .make-settings echo CFLAGS=$(CFLAGS) &gt;&gt; .make-settings echo LDFLAGS=$(LDFLAGS) &gt;&gt; .make-settings echo REDIS_CFLAGS=$(REDIS_CFLAGS) &gt;&gt; .make-settings echo REDIS_LDFLAGS=$(REDIS_LDFLAGS) &gt;&gt; .make-settings echo PREV_FINAL_CFLAGS=$(FINAL_CFLAGS) &gt;&gt; .make-settings echo PREV_FINAL_LDFLAGS=$(FINAL_LDFLAGS) &gt;&gt; .make-settings -(cd ../deps &amp;&amp; $(MAKE) $(DEPENDENCY_TARGETS)).PHONY: persist-settings # Prerequisites target.make-prerequisites: @touch $@# Clean everything, persist settings and build dependencies if anything changed#当设置有变化的时候清除并重新持久化设置ifneq ($(strip $(PREV_FINAL_CFLAGS)), $(strip $(FINAL_CFLAGS))).make-prerequisites: persist-settingsendififneq ($(strip $(PREV_FINAL_LDFLAGS)), $(strip $(FINAL_LDFLAGS))).make-prerequisites: persist-settingsendif# redis-server#redis-server可执行程序的链接，需要链接的静态链接文件包括hiredi和lua,还有final_libs$(REDIS_SERVER_NAME): $(REDIS_SERVER_OBJ) $(REDIS_LD) -o $@ $^ ../deps/hiredis/libhiredis.a ../deps/lua/src/liblua.a $(FINAL_LIBS)# redis-sentinel#redis-sentienl构建$(REDIS_SENTINEL_NAME): $(REDIS_SERVER_NAME) $(REDIS_INSTALL) $(REDIS_SERVER_NAME) $(REDIS_SENTINEL_NAME)# redis-check-rdb#redis-check-rdb的构建$(REDIS_CHECK_RDB_NAME): $(REDIS_SERVER_NAME) $(REDIS_INSTALL) $(REDIS_SERVER_NAME) $(REDIS_CHECK_RDB_NAME)# redis-check-aof#redis-check-aof的构建$(REDIS_CHECK_AOF_NAME): $(REDIS_SERVER_NAME) $(REDIS_INSTALL) $(REDIS_SERVER_NAME) $(REDIS_CHECK_AOF_NAME)# redis-cli#redis-cli的链接$(REDIS_CLI_NAME): $(REDIS_CLI_OBJ) $(REDIS_LD) -o $@ $^ ../deps/hiredis/libhiredis.a ../deps/linenoise/linenoise.o $(FINAL_LIBS)# redis-benchmark#redis-benchmark的链接$(REDIS_BENCHMARK_NAME): $(REDIS_BENCHMARK_OBJ) $(REDIS_LD) -o $@ $^ ../deps/hiredis/libhiredis.a $(FINAL_LIBS)dict-benchmark: dict.c zmalloc.c sds.c siphash.c $(REDIS_CC) $(FINAL_CFLAGS) $^ -D DICT_BENCHMARK_MAIN -o $@ $(FINAL_LIBS)# Because the jemalloc.h header is generated as a part of the jemalloc build,# building it should complete before building any other object. Instead of# depending on a single artifact, build all dependencies first.#将所有点c文件编译成.o文件 自动完成file.c 到file.o的对应%.o: %.c .make-prerequisites $(REDIS_CC) -c $&lt;clean: rm -rf $(REDIS_SERVER_NAME) $(REDIS_SENTINEL_NAME) $(REDIS_CLI_NAME) $(REDIS_BENCHMARK_NAME) $(REDIS_CHECK_RDB_NAME) $(REDIS_CHECK_AOF_NAME) *.o *.gcda *.gcno *.gcov redis.info lcov-html Makefile.dep dict-benchmark.PHONY: cleandistclean: clean -(cd ../deps &amp;&amp; $(MAKE) distclean) -(rm -f .make-*).PHONY: distcleantest: $(REDIS_SERVER_NAME) $(REDIS_CHECK_AOF_NAME) @(cd ..; ./runtest)test-sentinel: $(REDIS_SENTINEL_NAME) @(cd ..; ./runtest-sentinel)check: testlcov: $(MAKE) gcov @(set -e; cd ..; ./runtest --clients 1) @geninfo -o redis.info . @genhtml --legend -o lcov-html redis.infotest-sds: sds.c sds.h $(REDIS_CC) sds.c zmalloc.c -DSDS_TEST_MAIN $(FINAL_LIBS) -o /tmp/sds_test /tmp/sds_test.PHONY: lcovbench: $(REDIS_BENCHMARK_NAME) ./$(REDIS_BENCHMARK_NAME)32bit: @echo "" @echo "WARNING: if it fails under Linux you probably need to install libc6-dev-i386" @echo "" $(MAKE) CFLAGS="-m32" LDFLAGS="-m32"gcov: $(MAKE) REDIS_CFLAGS="-fprofile-arcs -ftest-coverage -DCOVERAGE_TEST" REDIS_LDFLAGS="-fprofile-arcs -ftest-coverage"noopt: $(MAKE) OPTIMIZATION="-O0"valgrind: $(MAKE) OPTIMIZATION="-O0" MALLOC="libc"helgrind: $(MAKE) OPTIMIZATION="-O0" MALLOC="libc" CFLAGS="-D__ATOMIC_VAR_FORCE_SYNC_MACROS"src/help.h: @../utils/generate-command-help.rb &gt; help.h#将构建完成的可执行程序安装到指定的目录，-p选项自行创建多层目录install: all @mkdir -p $(INSTALL_BIN) $(REDIS_INSTALL) $(REDIS_SERVER_NAME) $(INSTALL_BIN) $(REDIS_INSTALL) $(REDIS_BENCHMARK_NAME) $(INSTALL_BIN) $(REDIS_INSTALL) $(REDIS_CLI_NAME) $(INSTALL_BIN) $(REDIS_INSTALL) $(REDIS_CHECK_RDB_NAME) $(INSTALL_BIN) $(REDIS_INSTALL) $(REDIS_CHECK_AOF_NAME) $(INSTALL_BIN) @ln -sf $(REDIS_SERVER_NAME) $(INSTALL_BIN)/$(REDIS_SENTINEL_NAME) uname_S := $(shell sh -c &#39;uname -s 2&gt;/dev/null || echo not&#39;) 这一句-c让后面的字符串命令当成一个完成的命令来执行，从而避免向文件中写入东西的时候权限不够的问题。就算加上sudo也不行，因为里面的命令有&gt;,echo等很多个文件，所以只能用-c来当成一个整体来执行。参考 Makefile思路总结一下Redis Makefile的思路： 在默认规则也就是第一条规则之前，通过变量设置好编译的相关选项：LDFLAGS，相应的对应关系REDIS_SERVER_OBJ，将规则的target用变量表示好（方便all规则里面用作前置条件），比如REDIS_SERVER_NAME。 在第一条默认规则 all规则里面指定需要构建的东西 在第一规则后面先完成链接，再完成编译的规则 其他功能性规则如clean和distclean 也就是从上到下的结构是总-分。显示整个项目 ，然后是各个模块如redis-server，redis-cli的链接，然后是从源文件到obj文件的编译。 参考https://blog.csdn.net/bobchill/article/details/84647575]]></content>
      <categories>
        <category>源码阅读</category>
      </categories>
      <tags>
        <tag>redis</tag>
        <tag>Makefile</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[GCC的编译选项]]></title>
    <url>%2F2019%2F04%2F25%2F2019-04-25-GCC%E7%9A%84%E7%BC%96%E8%AF%91%E9%80%89%E9%A1%B9%2F</url>
    <content type="text"><![CDATA[GCC的编译选项Makefile 中的gcc的编译选项有很多，因此学习记录下。 这些选项在Makefile文件中常用CFLAGS（gcc 用在c语言的编译），CXXFLAGS（g++用在c++的编译）来表示。 程序编译的过程gcc 与 g++ 分别是 gnu 的 c &amp; c++ 编译器 gcc/g++ 在执行编译工作的时候，总共需要4步： 1、预处理,生成 .i 的文件[预处理器cpp] 2、将预处理后的文件转换成汇编语言, 生成文件 .s [编译器egcs] 3、将汇编代码变为目标代码(机器代码)生成 .o 的obj文件[汇编器as] 4、连接目标代码, 生成可执行程序 [链接器ld] 选项 选项 释义 -c 只激活预处理,编译,和汇编。只把程序做成obj文件，不是可执行文件（因为没有链接,有的程序中也没有main入口） -S 只激活预处理和编译，就是只把文件编译成为汇编代码。生成.s的汇编代码 -E 只激活预处理,不生成文件,你需要把它重定向到一个输出文件里面 例子：gcc -E hello.c &gt; pianoapan.txt -o 指定输出，缺省的时候,gcc 编译出来的文件是a.out -Wall 显示所有警告信息 -w 不生成任何警告信息。 -Wextra 打印出更多的警告信息，比开启 -Wall 打印的还多 -ansi 关闭gnu c中与ansi c不兼容的特性,激活ansi c的专有特性(包括禁止一些asm inline typeof关键字,以及UNIX,vax等预处理宏 -include file 包含某个代码,简单来说,就是便于某个文件需要另一个文件的时候,就可以用它设定,功能就相当于在代码中使用#include -Idir 添加dir目录为头文件搜索路径，如-I./ 在当前目录查找头文件 -I- 取消前一个参数的功能,所以一般在-Idir之后使用 -llib 指定编译的时候使用的库，gcc -lcurses hello.c 使用库curses进行编译 -std= 编译的标准,包括GNU99，c++11,c99,等等 -O2 编译器的优化选项的4个级别，-O0表示没有优化,-O1为缺省值，-O3优化级别最高 -Ldir 链接的时候，搜索库的路径 -L./ 在当前目录搜说 -g 产生调试信息，可以使用gdb调试可执行文件 -ggdb 此选项将尽可能的生成gdb的可以使用的调试信息. -static 禁止使用动态库，所以，编译出来的东西，一般都很大，也不需要什么 -share 此选项将尽量使用动态库，所以生成文件比较小，但是需要系统由动态库. -shared 创建一个动态链接库（不指定的话输出的是obj文件）gcc -fPIC -shared func.c -o libfunc.s -rdynamic 动态连接符号信息，用于动态连接功能。所有符号添加到动态符号表中（目的是能够通过使用 dlopen 来实现向后跟踪） -pedantic 用于保证代码规范满足ISO C和ISO C++标准, 不允许使用任何扩展以及不满足ISO C和C++的代码, 遵守 -std 选项指定的标准 -pthread 支持多线程, 使用pthread库 -fPIC PIC 是 position-independent code的意思, 此选项去除独立位置代码, 适合于动态链接 ar -r libhello.a hello.o #这里的ar相当于tar的作用，将多个目标打包。 makefile中用于创建静态链接库（就是把多个目标文件打包成一个） 参考https://blog.csdn.net/navyhu/article/details/46788559 https://blog.csdn.net/woshinia/article/details/11060797&gt; https://gcc.gnu.org/onlinedocs/]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>gcc</tag>
        <tag>make</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[青蛙跳台阶问题]]></title>
    <url>%2F2019%2F04%2F17%2F2019-04-17-%E9%9D%92%E8%9B%99%E8%B7%B3%E5%8F%B0%E9%98%B6%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[青蛙跳台阶问题一只青蛙一次可以跳上1级台阶，也可以跳上2级。求该青蛙跳上一个n级的台阶总共有多少种跳法（先后次序不同算不同的结果）。 公式不能在hexo上显示出来 题目来源： https://www.nowcoder.com/practice/8c82a5b80378478f9484d87d1c5f12a4?tpId=13&amp;tqId=11161&amp;tPage=1&amp;rp=1&amp;ru=/ta/coding-interviews&amp;qru=/ta/coding-interviews/question-ranking 解题思路：函数思想，把n阶台阶的调法看成是关于n的函数 f(n)。当n&gt;2的时候： 假设第一次跳一个台阶，那么还剩n-1个台阶需要跳，也就是还有f(n-1)的跳法。 假设第一次跳两个台阶，那么还剩n-2个台阶需要跳，也就是还有f(n-2)的跳法 所以n阶的跳法总共有f(n-1) + f(n-2) 种，也就是 f(n) = f(n-1) +f(n-2)。 所以函数就是 ：$$f(n)=\begin{cases}0&amp; \text{n=0}\1&amp; \text{n=1}\2&amp; \text {n=2}\f(n-1)+f(n-2)&amp; \text {n&gt;2}\end{cases}$$也就是一个斐波那契数列，代码也就比较简单了。参考斐波那契数列的解法: https://github.com/BraveY/Coding/blob/master/%E5%89%91%E6%8C%87offer/Fibonacci.cc 代码为： 1234567891011121314151617class Solution &#123;public: int jumpFloor(int number) &#123; int result[3] = &#123;0,1,2&#125;; if(number&lt;3) return result[number]; int fib_one = result[1]; int fib_two = result[2]; int fib; for(int i=3; i&lt;=number; i++)&#123; fib = fib_one + fib_two; fib_one = fib_two; fib_two = fib; &#125; return fib; &#125;&#125;; 变种题目：一只青蛙一次可以跳上1级台阶，也可以跳上2级……它也可以跳上n级。求该青蛙跳上一个n级的台阶总共有多少种跳法。 思路也是一样的：第一次跳1级台阶，则有f(n-1)的解法，第一次跳2级台阶，则有f(n-2)的解法，第一次跳n-1级台阶，则有f(2)的解法， 第一次跳n级台阶则还有一种解法。用f(0)表示第一次跳n级的情况,f(0)=1。 归纳成函数就是：$$f(n)=\begin{cases}1&amp; \text{n=0}\1&amp; \text{n=1}\f(n-1)+f(n-2)…+f(1)+f(0)&amp; \text {n&gt;1}\end{cases}$$所以代码为： 123456789101112131415class Solution &#123;public: int jumpFloorII(int number) &#123; vector&lt;int&gt; result; result.push_back(1); // f(0) =1 ; for(int i=1; i&lt;=number; i++)&#123; int sum = 0; for(int j=0; j&lt;i; j++)&#123; // f(n)=f(n-1)+f(n-2)+...f(1)+f(0) sum += result[j]; &#125; result.push_back(sum); &#125; return result[number]; &#125;&#125;; 另一个斐波那契数列数列问题： 矩形覆盖https://www.nowcoder.com/practice/72a5a919508a4251859fb2cfb987a0e6?tpId=13&amp;tqId=11163&amp;rp=1&amp;ru=/ta/coding-interviews&amp;qru=/ta/coding-interviews/question-ranking 我们可以用21的小矩形横着或者竖着去覆盖更大的矩形。请问用n个21的小矩形无重叠地覆盖一个2*n的大矩形，总共有多少种方法？ 最开始的时候没有想清楚，以为不是斐波那契数列。 思路： 同样的方法为n的函数：f(n); 对于n=1的情况，只能竖着放：所以f(1)=1; n=2的时候，竖着放之后就变成了f(1)种方法，横着放的时候只有一种，总共有两种，所以f(2)=2; 所以函数为：$$f(n)=\begin{cases}0&amp; \text{n=0}\1&amp; \text{n=1}\2&amp; \text {n=2}\f(n-1)+f(n-2)&amp; \text {n&gt;2}\end{cases}$$因此代码也是同第一个青蛙跳台阶一样的。 代码： 1234567891011121314151617//https://www.nowcoder.com/practice/72a5a919508a4251859fb2cfb987a0e6?tpId=13&amp;tqId=11163&amp;rp=1&amp;ru=/ta/coding-interviews&amp;qru=/ta/coding-interviews/question-rankingclass Solution &#123;public: int rectCover(int number) &#123; int result[3] = &#123;0,1,2&#125;; if(number&lt;3) return result[number]; int fib_one = result[1]; int fib_two = result[2]; int fib; for(int i=3; i&lt;=number; i++)&#123; fib = fib_one + fib_two; fib_one = fib_two; fib_two = fib; &#125; return fib; &#125;&#125;; 总结总结一下，对于斐波那契数列问题思路都是一样： 输出是输入的函数， f(n) 考虑第一次是如何选择的，就可以把问题给切分出来了。]]></content>
      <categories>
        <category>刷题</category>
      </categories>
      <tags>
        <tag>斐波拉契数列</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux shell脚本计算运行时间]]></title>
    <url>%2F2019%2F04%2F10%2F2019-04-10-Linux-shell%E8%84%9A%E6%9C%AC%E8%AE%A1%E7%AE%97%E8%BF%90%E8%A1%8C%E6%97%B6%E9%97%B4%2F</url>
    <content type="text"><![CDATA[Linux shell脚本计算运行时间这个功能经常用但是，总是现用现查，很麻烦。 代码 123456789101112131415161718192021222324252627282930313233343536# filename: msec_diff.shfunction timediff() &#123;# time format:date +"%s.%N", such as 1502758855.907197692 start_time=$1 end_time=$2 start_s=$&#123;start_time%.*&#125; start_nanos=$&#123;start_time#*.&#125; end_s=$&#123;end_time%.*&#125; end_nanos=$&#123;end_time#*.&#125; # end_nanos &gt; start_nanos? # Another way, the time part may start with 0, which means # it will be regarded as oct format, use "10#" to ensure # calculateing with decimal if [ "$end_nanos" -lt "$start_nanos" ];then end_s=$(( 10#$end_s - 1 )) end_nanos=$(( 10#$end_nanos + 10**9 )) fi # get timediff time=$(( 10#$end_s - 10#$start_s )).`printf "%03d\n" $(( (10#$end_nanos - 10#$start_nanos)/10**6 ))` echo $time&#125;#start=$(date +"%s.%N")# Now exec some command#end=$(date +"%s.%N")# here give the valuesstart=1502758855.907197692end=1502758865.066894173timediff $start $end 参考https://www.cnblogs.com/f-ck-need-u/p/7426987.html]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[gdb 调试]]></title>
    <url>%2F2019%2F04%2F03%2F2019-04-03-gdb-%E8%B0%83%E8%AF%95%2F</url>
    <content type="text"><![CDATA[gdb调试以前学习过，用得少，又忘记了，现在刚好为了调试redis 的dict 模块，所以再次记录。 使用摘自参考&lt;https://linuxtools-rst.readthedocs.io/zh_CN/latest/tool/gdb.html&gt;。 主要是补充实例 对C/C++程序的调试，需要在编译前就加上-g选项: 1$g++ -g hello.cpp -o hello 自己的Makefile里面修改成： 12dict-benchmark: dict.c sds.c siphash.c $(CC) -g -o $@ $^ 但是好像没加之前也是可以直接就使用gdb 了？ 不知道为什么（可以使用但是出错不会显示所在的行，相当于没有调试） 调试可执行文件: 1$gdb &lt;program&gt; program也就是你的执行文件，一般在当前目录下。 调试core文件(core是程序非法执行后core dump后产生的文件): 12$gdb &lt;program&gt; &lt;core dump file&gt;$gdb program core.11127 调试服务程序: 12$gdb &lt;program&gt; &lt;PID&gt;$gdb hello 11127 如果你的程序是一个服务程序，那么你可以指定这个服务程序运行时的进程ID。gdb会自动attach上去，并调试他。program应该在PATH环境变量中搜索得到。 gdb交互命令启动gdb后，进入到交互模式，通过以下命令完成对程序的调试；注意高频使用的命令一般都会有缩写，熟练使用这些缩写命令能提高调试的效率； 运行 run：简记为 r ，其作用是运行程序，当遇到断点后，程序会在断点处停止运行，等待用户输入下一步的命令。 continue （简写c ）：继续执行，到下一个断点处（或运行结束） next：（简写 n），单步跟踪程序，当遇到函数调用时，也不进入此函数体；此命令同 step 的主要区别是，step 遇到用户自定义的函数，将步进到函数中去运行，而 next 则直接调用函数，不会进入到函数体内。 step （简写s）：单步调试如果有函数调用，则进入函数；与命令n不同，n是不进入调用的函数的 until：当你厌倦了在一个循环体内单步跟踪时，这个命令可以运行程序直到退出循环体。 until+行号： 运行至某行，不仅仅用来跳出循环 finish： 运行程序，直到当前函数完成返回，并打印函数返回时的堆栈地址和返回值及参数值等信息。 call 函数(参数)：调用程序中可见的函数，并传递“参数”，如：call gdb_test(55) quit：简记为 q ，退出gdb 设置断点 break n （简写b n）:在第n行处设置断点 （可以带上代码路径和代码名称： b OAGUPDATE.cpp:578） b fn1 if a＞b：条件断点设置 break func（break缩写为b）：在函数func()的入口处设置断点，如：break cb_button delete 断点号n：删除第n个断点 disable 断点号n：暂停第n个断点 enable 断点号n：开启第n个断点 clear 行号n：清除第n行的断点 info b （info breakpoints） ：显示当前程序的断点设置情况 delete breakpoints：清除所有断点： 查看源代码 list ：简记为 l ，其作用就是列出程序的源代码，默认每次显示10行。 list 行号：将显示当前文件以“行号”为中心的前后10行代码，如：list 12 list 函数名：将显示“函数名”所在函数的源代码，如：list main list ：不带参数，将接着上一次 list 命令的，输出下边的内容。 打印表达式 print 表达式：简记为 p ，其中“表达式”可以是任何当前正在被测试程序的有效表达式，比如当前正在调试C语言的程序，那么“表达式”可以是任何C语言的有效表达式，包括数字，变量甚至是函数调用。 print a：将显示整数 a 的值 print ++a：将把 a 中的值加1,并显示出来 print name：将显示字符串 name 的值 print gdb_test(22)：将以整数22作为参数调用 gdb_test() 函数 print gdb_test(a)：将以变量 a 作为参数调用 gdb_test() 函数 display 表达式：在单步运行时将非常有用，使用display命令设置一个表达式后，它将在每次单步进行指令后，紧接着输出被设置的表达式及值。如： display a watch 表达式：设置一个监视点，一旦被监视的“表达式”的值改变，gdb将强行终止正在被调试的程序。如： watch a whatis ：查询变量或函数 info function： 查询函数 扩展info locals： 显示当前堆栈页的所有变量 查询运行信息 where/bt ：当前运行的堆栈列表； bt backtrace 显示当前调用堆栈 up/down 改变堆栈显示的深度 set args 参数:指定运行时的参数 show args：查看设置好的参数 info program： 来查看程序的是否在运行，进程号，被暂停的原因。 分割窗口 layout：用于分割窗口，可以一边查看代码，一边测试： layout src：显示源代码窗口 layout asm：显示反汇编窗口 layout regs：显示源代码/反汇编和CPU寄存器窗口 layout split：显示源代码和反汇编窗口 Ctrl + L：刷新窗口 实例调试程序dict-benchmark 开始调试： 1234567891011121314151617root@hw103:/home/yky/test/redis_dict/dict-benchmark# gdb dict-benchmark GNU gdb (Ubuntu 7.11.1-0ubuntu1~16.5) 7.11.1Copyright (C) 2016 Free Software Foundation, Inc.License GPLv3+: GNU GPL version 3 or later &lt;http://gnu.org/licenses/gpl.html&gt;This is free software: you are free to change and redistribute it.There is NO WARRANTY, to the extent permitted by law. Type &quot;show copying&quot;and &quot;show warranty&quot; for details.This GDB was configured as &quot;x86_64-linux-gnu&quot;.Type &quot;show configuration&quot; for configuration details.For bug reporting instructions, please see:&lt;http://www.gnu.org/software/gdb/bugs/&gt;.Find the GDB manual and other documentation resources online at:&lt;http://www.gnu.org/software/gdb/documentation/&gt;.For help, type &quot;help&quot;.Type &quot;apropos word&quot; to search for commands related to &quot;word&quot;...Reading symbols from dict-benchmark...done.(gdb) 使用 r 运行： 1234567891011(gdb) rStarting program: /home/yky/test/redis_dict/dict-benchmark/dict-benchmark Add elements to dictAdd ret0 is :0, ht[0].used:1, ht[0].size:4,ht[1].used:0, ht[1].size:0Add ret1 is :0, ht[0].used:2, ht[0].size:4,ht[1].used:0, ht[1].size:0Add ret2 is :0, ht[0].used:3, ht[0].size:4,ht[1].used:0, ht[1].size:0Program received signal SIGSEGV, Segmentation fault.0x000000000040288b in _dictKeyIndex (d=0x60a050, key=0x60a011, hash=3050426978, existing=0x0) at dict.c:975975 if (key==he-&gt;key || dictCompareKeys(d, key, he-&gt;key)) &#123;(gdb) 在_dictKeyIndex ()函数也就是计算索引的时候出错。 l 列出代码： 1234567891011(gdb) l970 for (table = 0; table &lt;= 1; table++) &#123;971 idx = hash &amp; d-&gt;ht[table].sizemask;972 /* Search if this slot does not already contain the given key */973 he = d-&gt;ht[table].table[idx];974 while(he) &#123;975 if (key==he-&gt;key || dictCompareKeys(d, key, he-&gt;key)) &#123;976 if (existing) *existing = he;977 return -1;978 &#125;979 he = he-&gt;next; 在975行加入断点 b n 12(gdb) b 975Breakpoint 2 at 0x402887: file dict.c, line 975. 输出对应变量的值：print 12(gdb) print key $1 = (const void *) 0x60a011 参考https://linuxtools-rst.readthedocs.io/zh_CN/latest/tool/gdb.html]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>gdb</tag>
        <tag>工具</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker 学习]]></title>
    <url>%2F2019%2F04%2F01%2F2019-04-01-Docker-%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[Docker 学习之前一直听说容器可以免去配置环境的麻烦，但是一直没有机会接触，现在刚好有机会可以使用。 三大基础镜像、容器、仓库 类比的话：镜像是类（iso），容器是实例（操作系统），仓库类似于git的仓库。 镜像的构建是一层层的继承而来的，镜像和容器都是文件，容器退出的时候容器文件依然存在。除非手动使用-rm指定，才会删除。 命令加载镜像，进入一个新的容器：docker run image:tag command 实例 摘自：https://yeasy.gitbooks.io/docker_practice/image/pull.html 123docker run -it --rm \ ubuntu:18.04 \ bash docker run 就是运行容器的命令 从镜像中新建一个容器 -it：这是两个参数，一个是 -i：交互式操作，一个是 -t 终端。我们这里打算进入 bash 执行一些命令并查看返回结果，因此我们需要交互式终端。 --rm：这个参数是说容器退出后随之将其删除。默认情况下，为了排障需求，退出的容器并不会立即删除，除非手动 docker rm。我们这里只是随便执行个命令，看看结果，不需要排障和保留结果，因此使用 --rm 可以避免浪费空间。 ubuntu:18.04：这是指用 ubuntu:18.04 镜像为基础来启动容器。 bash：放在镜像名后的是命令，这里我们希望有个交互式 Shell，因此用的是 bash。 退出: 在容器中exit 进入容器： docker exec 进入一个已有的容器。 （容器需要已经运行） dcoker cp 容器的复制 docker ps 列出启动容器 docker ps -a 列出所有容器包括关闭的。 启动之前关闭的容器： docker start container-name ， 需要先启动容器，才能执行docker exec container-name 端口映射https://blog.csdn.net/wanglei_storage/article/details/48471753 参考https://juejin.im/entry/5b19e350e51d45069f5e1d66 https://yeasy.gitbooks.io/docker_practice/basic_concept/container.html https://blog.csdn.net/u010246789/article/details/53958662]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>容器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[计算Linux系统的CPU利用率]]></title>
    <url>%2F2019%2F03%2F31%2F2019-03-31-%E8%AE%A1%E7%AE%97Linux%E7%B3%BB%E7%BB%9F%E7%9A%84CPU%E5%88%A9%E7%94%A8%E7%8E%87%2F</url>
    <content type="text"><![CDATA[计算Linux系统的CPU利用率通过读取系统的/proc/stat 信息来计算CPU的利用率 cpu 信息的读取摘自参考博客：https://blog.csdn.net/x_i_y_u_e/article/details/50684508 在Linux/Unix下，CPU利用率分为用户态，系统态和空闲态，分别表示CPU处于用户态执行的时间，系统内核执行的时间，和空闲系统进程执行的时间。平时所说的CPU利用率是指：CPU执行非系统空闲进程的时间 / CPU总的执行时间。 在Linux的内核中，有一个全局变量：Jiffies。 Jiffies代表时间。它的单位随硬件平台的不同而不同。系统里定义了一个常数HZ，代表每秒种最小时间间隔的数目。这样jiffies的单位就是1/HZ。Intel平台jiffies的单位是1/100秒，这就是系统所能分辨的最小时间间隔了。每个CPU时间片，Jiffies都要加1。 CPU的利用率就是用执行用户态+系统态的Jiffies除以总的Jifffies来表示。 在Linux系统中，可以用/proc/stat文件来计算cpu的利用率(详细的解释可参考：http://www.linuxhowtos.org/System/procstat.htm)。这个文件包含了所有CPU活动的信息，该文件中的所有值都是从系统启动开始累计到当前时刻。 在本机上的信息如下： 123456789101112131415161718192021222324252627282930313233 root@hw103:/home/yky# cat/proc/stat cpu 7283854 35392 293546 204419077 75835 0 8385 0 0 0cpu0 365010 48 18204 8453603 767 0 4306 0 0 0cpu1 292817 9 14990 8526563 1358 0 2114 0 0 0cpu2 286689 0 11880 8538662 1033 0 752 0 0 0cpu3 287106 14624 12945 8523209 641 0 320 0 0 0cpu4 293293 0 11784 8532282 604 0 147 0 0 0cpu5 371312 2824 13669 8408187 40794 0 406 0 0 0cpu6 358116 10934 14014 8453775 1230 0 68 0 0 0cpu7 313971 6281 12243 8504303 1575 0 28 0 0 0cpu8 318084 0 11598 8506770 2036 0 15 0 0 0cpu9 294503 0 11137 8530318 2185 0 10 0 0 0cpu10 307922 144 12434 8516570 1177 0 15 0 0 0cpu11 291752 0 11502 8533957 1128 0 4 0 0 0cpu12 315096 0 15927 8503001 3528 0 3 0 0 0cpu13 375976 0 17927 8442873 2041 0 1 0 0 0cpu14 299344 0 10140 8523716 2818 0 1 0 0 0cpu15 288470 3 10146 8538685 1240 0 0 0 0 0cpu16 301148 0 10681 8523612 2185 0 0 0 0 0cpu17 263183 4 9149 8565345 771 0 0 0 0 0cpu18 262518 370 10343 8562955 2105 0 11 0 0 0cpu19 280230 3 10399 8546414 1227 0 6 0 0 0cpu20 278962 0 10346 8547585 1221 0 9 0 0 0cpu21 277042 143 11502 8547940 1048 0 2 0 0 0cpu22 275560 0 9458 8549093 1271 0 153 0 0 0cpu23 285740 0 11118 8539648 1838 0 6 0 0 0intr 91288599 43 2 0 0 0 0 0 0 1 0 0 0 4 0 0 0 41 0 2 0 0 0 0 0 0 0 334158 0 1 2473208 45518 96917 44876 138077 45263 45258 54441 0 0 44198 44198 44198 44198 44198 44198 44198 44198 0 0 44198 44198 44198 44198 44198 44198 44198 44198 0 0 44199 44199 44199 44199 44199 44199 44199 44199 0 0 44199 44199 44199 44199 44199 44199 44199 44199 0 0 44198 44198 44198 44198 44198 44198 44198 44198 0 0 44198 44198 44198 44198 44198 44198 44198 44198 0 0 44199 44199 44199 44199 44199 44199 44199 44199 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0ctxt 42731429btime 1553933982processes 190449procs_running 5procs_blocked 0softirq 57291816 8 26401645 17536 5419485 334063 0 1044 10019160 0 15098875 第一行cpu是总的cpu信息，其他的cpu0-cpu23 是24个核的信息。 计算cpu利用率只用到前7个参数， 对应的参数解释为： 12 user nice system idle iowait irq softirqcpu 7283854 35392 293546 204419077 75835 0 8385 user (7283854) 从系统启动开始累计到当前时刻，用户态的CPU时间（单位：jiffies） ，不包含 nice值为负进程。1jiffies=0.01秒nice (35392) 从系统启动开始累计到当前时刻，nice值为负的进程所占用的CPU时间（单位：jiffies）system (293546) 从系统启动开始累计到当前时刻，核心时间（单位：jiffies）idle (204419077) 从系统启动开始累计到当前时刻，除硬盘IO等待时间以外其它等待时间（单位：jiffies）iowait (75835) 从系统启动开始累计到当前时刻，硬盘IO等待时间（单位：jiffies） ，irq (0) 从系统启动开始累计到当前时刻，硬中断时间（单位：jiffies）softirq (8385) 从系统启动开始累计到当前时刻，软中断时间（单位：jiffies） CPU时间=user+system+nice+idle+iowait+irq+softirq “intr”这行给出中断的信息，第一个为自系统启动以来，发生的所有的中断的次数；然后每个数对应一个特定的中断自系统启动以来所发生的次数。“ctxt”给出了自系统启动以来CPU发生的上下文交换的次数。“btime”给出了从系统启动到现在为止的时间，单位为秒。“processes (total_forks) 自系统启动以来所创建的任务的个数目。“procs_running”：当前运行队列的任务的数目。“procs_blocked”：当前被阻塞的任务的数目。 计算cpu利用率的方法就是计算出在一段时间里面，cpu工作的时间/总得时间 12cpu usage=(idle2-idle1)/(cpu2-cpu1)*100cpu usage=[(user_2 +sys_2+nice_2) - (user_1 + sys_1+nice_1)]/(total_2 - total_1)*100 第二中方法只把user+sys+nice 这三个时间看作cpu的工作时间，因为其他的几个比较小。 shell脚本1234567891011121314151617181920212223242526#!/bin/bash##echo user nice system idle iowait irq softirqcpulog_start=$(cat /proc/stat | grep 'cpu'| awk 'NR==1&#123;print $2 "\t" $3 "\t" $4 "\t" $5 "\t" $6 "\t" $7 "\t" $8&#125;' )cpu_use_start=$(echo $cpulog_start | awk '&#123;print $1+$2+$3&#125;')cpu_iowait_start=$(echo $cpulog_start | awk '&#123;print $5&#125;')cpu_total_start=$(echo $cpulog_start | awk '&#123;print $1+$2+$3+$4+$5+$6+$7&#125;')sleep 10cpulog_end=$(cat /proc/stat | grep 'cpu'| awk 'NR==1&#123;print $2 "\t" $3 "\t" $4 "\t" $5 "\t" $6 "\t" $7 "\t" $8&#125;' )cpu_use_end=$(echo $cpulog_end | awk '&#123;print $1+$2+$3&#125;')cpu_iowait_end=$(echo $cpulog_end | awk '&#123;print $5&#125;')cpu_total_end=$(echo $cpulog_end | awk '&#123;print $1+$2+$3+$4+$5+$6+$7&#125;')cpu_use_diff=`expr $cpu_use_end - $cpu_use_start`cpu_iowait_diff=`expr $cpu_iowait_end - $cpu_iowait_start`cpu_total_diff=`expr $cpu_total_end - $cpu_total_start`cpu_use_rate=`expr $cpu_use_diff/$cpu_total_diff*100 | bc -l`cpu_iowait_rate=`expr $cpu_iowait_diff/$cpu_total_diff*100 | bc -l`echo "---------------cpuinfo----------------------"echo "cpu_usage_rate (%) : $cpu_use_rate"echo "cpu_iowait_rate (%): $cpu_iowait_rate" 主要的知识点讲解： 1cpulog_start=$(cat /proc/stat | grep 'cpu'| awk 'NR==1&#123;print $2 "\t" $3 "\t" $4 "\t" $5 "\t" $6 "\t" $7 "\t" $8&#125;' ) 这一句先将/proc/stat文件的信息读取出来然后用管道| 传递给grep 命令 ,grep 将包含cpu的信息给提取出来 cat /proc/stat | grep &#39;cpu&#39; 输出为： 1234567891011121314151617181920212223242526root@hw103:/home/yky# cat /proc/stat | grep 'cpu'cpu 7645369 35392 318219 206250476 80895 0 9870 0 0 0cpu0 365256 48 18792 8544685 767 0 5678 0 0 0cpu1 292983 9 15427 8618292 1389 0 2206 0 0 0cpu2 287020 0 12884 8629895 1033 0 760 0 0 0cpu3 288372 14624 13910 8613386 681 0 320 0 0 0cpu4 293707 0 13074 8623117 646 0 147 0 0 0cpu5 390012 2824 15130 8477387 44027 0 418 0 0 0cpu6 362140 10934 15217 8541127 1233 0 69 0 0 0cpu7 377620 6281 12915 8532734 1700 0 28 0 0 0cpu8 333520 0 12524 8582987 2100 0 15 0 0 0cpu9 348913 0 12619 8567005 2453 0 10 0 0 0cpu10 333584 144 14002 8581939 1297 0 15 0 0 0cpu11 292980 0 12966 8623861 1137 0 4 0 0 0cpu12 350188 0 16793 8559301 4017 0 3 0 0 0cpu13 430200 0 19278 8479849 2344 0 1 0 0 0cpu14 312421 0 11483 8601843 2906 0 1 0 0 0cpu15 343656 3 10768 8575706 1268 0 0 0 0 0cpu16 302673 0 12190 8613170 2190 0 0 0 0 0cpu17 263473 4 9906 8656857 771 0 0 0 0 0cpu18 263094 370 11278 8653940 2165 0 11 0 0 0cpu19 281216 3 11166 8637253 1280 0 6 0 0 0cpu20 280412 0 11645 8637433 1221 0 9 0 0 0cpu21 277219 143 11967 8639929 1048 0 2 0 0 0cpu22 275894 0 10291 8640508 1271 0 153 0 0 0cpu23 298806 0 11985 8618261 1939 0 6 0 0 0 awk 命令之后使用awk命令再次进行操作。这个命令之前用的很少，参考《鸟哥的Linux私房菜》介绍： sed常用于一整行的处理，awk则倾向于将一行分成数个“字段”来处理，awk适合处理小型的数据。 用法为： awk &#39;条件类型1{操作1} 条件类型1{操作2}...&#39; filename 变量名称 意义 NF 每一行（$0） 拥有的字段总数 NR awk当前处理的第几行数据 FS 目前的分割符，默认空格键 1cpulog_start=$(cat /proc/stat | grep 'cpu'| awk 'NR==1&#123;print $2 "\t" $3 "\t" $4 "\t" $5 "\t" $6 "\t" $7 "\t" $8&#125;' ) NR==1 限定条件为第一行，因为第一行的数据才是cpu的总信息，{}里面的操作是输出字段，$N 就是第N个字段。 123 $1 $2 $3 $4 $5 $6 $7 $8 user nice system idle iowait irq softirqcpu 7283854 35392 293546 204419077 75835 0 8385 expr1cpu_use_diff=`expr $cpu_use_end - $cpu_use_start` 使用expr 执行变量计算，然后是 进行反引用将值赋值给cpu_use_diff 注意shell 脚本中= 不能用空格分开 需要直接相邻 bc 命令bc 命令是任意精度计算器语言，通常在linux下当计算器用。 简单的描述参考：http://www.runoob.com/linux/linux-comm-bc.html 而expr命令不支持小数运算，所以需要使用bc进行计算。 语法为： 1bc(选项)(参数) 选项值 -i：强制进入交互式模式； -l：定义使用的标准数学库 ； -w：对POSIX bc的扩展给出警告信息； -q：不打印正常的GNU bc环境信息； -v：显示指令版本信息； -h：显示指令的帮助信息。 参数 文件：指定包含计算任务的文件。 参考https://blog.csdn.net/x_i_y_u_e/article/details/50684508]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis设计与实现读书笔记——第8章 对象]]></title>
    <url>%2F2019%2F03%2F29%2F2019-03-29-Redis%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B0%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%E2%80%94%E2%80%94%E7%AC%AC8%E7%AB%A0-%E5%AF%B9%E8%B1%A1%2F</url>
    <content type="text"><![CDATA[Redis设计与实现读书笔记——第8章 对象Redis 并没有直接使用sds、dict等数据结构来实现键值对数据库， 而是基于这些数据结构创建了一个对象系统， 这个系统包含字符串对象、列表对象、哈希对象、集合对象和有序集合对象这五种类型的对象， 每种对象都用到了至少一种前面所介绍的数据结构。 简介对象的好处： 根据对象的类型来判断是否可以执行给定的命令。 针对不同的使用场景， 为对象设置多种不同的数据结构实现， 从而优化对象在不同场景下的使用效率。 对象的特性： 基于引用计数技术的内存回收机制（和java的是否原理相似） 通过引用计数技术实现对象共享机制，多个键共享同一个对象来节约内存 带有访问时间记录信息，可以用来删除空转时长较大的键 8.1 对象的类型与编码Redis 使用对象来表示数据库中的键和值，创建一个新的键值对的时候，至少包含两个对象：1. 键对象 2. 值对象 对象都由一个 redisObject 结构表示，保存数据相关的属性 1234567891011121314typedef struct redisObject &#123; // 对象类型 unsigned type:4; // 编码 unsigned encoding:4; //lru 时钟 记录最后被访问的时间，也就是空转时长 unsigned lru:LRU_BITS; /* LRU time (relative to global lru_clock) or * LFU data (least significant 8 bits frequency * and most significant 16 bits decreas time). */ // 引用计数 实现内存自动回收等。 int refcount; // 指向底层实现数据结构的指针 void *ptr;&#125; robj; ptr指向的就是之前的sds，dict这些数据结构的内存地址。 变量申明加冒号的用法： 是C语言的位域的用法。:后面的数字用来限定成员变量占用的位数。冒号后面的数字说明只会用到对应多少个bit位。type只会用到4个bit，encoding 也只会用的4个bit。变量占用的内存不再是有类型决定，而是位域。 8.1.1 类型type属性的值包括5种： 类型常量 对象的名称 REDIS_STRING 字符串对象 REDIS_LIST 列表对象 REDIS_HASH 哈希对象 REDIS_SET 集合对象 REDIS_ZSET 有序集合对象 键对象只能是字符串对象，而值对象则5种之一。所以执行TYPE命令返回的是键值对中值对象的类型。 type命令的 对象 对象 type 属性的值 TYPE 命令的输出 字符串对象 REDIS_STRING &quot;string&quot; 列表对象 REDIS_LIST &quot;list&quot; 哈希对象 REDIS_HASH &quot;hash&quot; 集合对象 REDIS_SET &quot;set&quot; 有序集合对象 REDIS_ZSET &quot;zset&quot; 8.2 编码和底层实现ptr指向底层数据结构，而encoding则决定了具体应该指向什么样的数据结构实现。之所以不能用type来决定指向的具体数据结构，是因为同一种对象，但是底层实现会有不同的数据结构。 编码常量 编码所对应的底层数据结构 REDIS_ENCODING_INT long 类型的整数 REDIS_ENCODING_EMBSTR embstr 编码的简单动态字符串 REDIS_ENCODING_RAW 简单动态字符串 REDIS_ENCODING_HT 字典 REDIS_ENCODING_LINKEDLIST 双端链表 REDIS_ENCODING_ZIPLIST 压缩列表 REDIS_ENCODING_INTSET 整数集合 REDIS_ENCODING_SKIPLIST 跳跃表和字典 每种类型的对象都至少使用了两种不同的编码，对应关系为： 类型 编码 对象 REDIS_STRING REDIS_ENCODING_INT 使用整数值实现的字符串对象。 REDIS_STRING REDIS_ENCODING_EMBSTR 使用 embstr 编码的简单动态字符串实现的字符串对象。 REDIS_STRING REDIS_ENCODING_RAW 使用简单动态字符串实现的字符串对象。 REDIS_LIST REDIS_ENCODING_ZIPLIST 使用压缩列表实现的列表对象。 REDIS_LIST REDIS_ENCODING_LINKEDLIST 使用双端链表实现的列表对象。 REDIS_HASH REDIS_ENCODING_ZIPLIST 使用压缩列表实现的哈希对象。 REDIS_HASH REDIS_ENCODING_HT 使用字典实现的哈希对象。 REDIS_SET REDIS_ENCODING_INTSET 使用整数集合实现的集合对象。 REDIS_SET REDIS_ENCODING_HT 使用字典实现的集合对象。 REDIS_ZSET REDIS_ENCODING_ZIPLIST 使用压缩列表实现的有序集合对象。 REDIS_ZSET REDIS_ENCODING_SKIPLIST 使用跳跃表和字典实现的有序集合对象。 使用 OBJECT ENCODING 命令可以查看一个数据库键的值对象的编码： 12345redis&gt; SET msg &quot;hello wrold&quot;OKredis&gt; OBJECT ENCODING msg&quot;embstr&quot; 不同编码的对象所对应的OBJECT ENCODING输出： 表 8-5 OBJECT ENCODING 对不同编码的输出 对象所使用的底层数据结构 编码常量 OBJECT ENCODING 命令输出 整数 REDIS_ENCODING_INT &quot;int&quot; embstr 编码的简单动态字符串（SDS） REDIS_ENCODING_EMBSTR &quot;embstr&quot; 简单动态字符串 REDIS_ENCODING_RAW &quot;raw&quot; 字典 REDIS_ENCODING_HT &quot;hashtable&quot; 双端链表 REDIS_ENCODING_LINKEDLIST &quot;linkedlist&quot; 压缩列表 REDIS_ENCODING_ZIPLIST &quot;ziplist&quot; 整数集合 REDIS_ENCODING_INTSET &quot;intset&quot; 跳跃表和字典 REDIS_ENCODING_SKIPLIST &quot;skiplist&quot; 使用encoding属性来设定对象指向的具体数据结构实现的好处：灵活与效率。根据不同场景来给同一种对象设置不同的数据结构实现。 举个例子， 在列表对象包含的元素比较少时， Redis 使用压缩列表作为列表对象的底层实现： 因为压缩列表比双端链表更节约内存， 并且在元素数量较少时， 在内存中以连续块方式保存的压缩列表比起双端链表可以更快被载入到缓存中； 随着列表对象包含的元素越来越多， 使用压缩列表来保存元素的优势逐渐消失时， 对象就会将底层实现从压缩列表转向功能更强、也更适合保存大量元素的双端链表上面； 是不是也可以理解成多态呢？ 8.2 字符串对象字符串对象的编码可以是 int 、 raw 或者 embstr 。 保存的对象是整数，而且可以用long类型表示：ptr指针指向一个long类型的内存地址。（是不是不用指向sdshdr了），然后将encoding 设置为REDIS_ENCODING_INT (应该在源码中有个宏定义) 保存的对象是字符串值，长度小于44字节（书上的39字节，但是先版本已经更新）。这种短字符串对象，直接只调用一次内存分配函数来分配一块连续的空间 依次包含redisObject和sdshdr两个结构。 字符串长度大于等于44字节的时候使用raw编码。会调用两次内存分配函数来创建redisObject结构和sdshdr结构。 embstr编码的好处： 只用分配一次内存，raw编码需要两次 释放embstr的sds也只需要一次内存释放函数，raw两次 embstr的所有数据（对象结构，字符串结构）在连续的一块内存里面，从而可以更好地利用缓存带来的优势 embstr和raw的示意图，摘自书上，但是注意sds的结构稍有变化。 raw编码： embstr编码： 注意： long double类型的浮点数是转换成字符串值来保存的。执行的时候取出字符串再转换成long double 类型。 值 编码 可以用 long 类型保存的整数。 int 可以用 long double 类型保存的浮点数。 embstr 或者 raw 字符串值， 或者因为长度太大而没办法用 long 类型表示的整数， 又或者因为长度太大而没办法用 long double 类型表示的浮点数。 embstr 或者 raw 8.2.1 编码的转换当保存的值发生变化的时候会进行转换，比如保存的整数值变成了字符串，那么编码从int 变成raw或者embstr。 注意： Redis 没有为embstr编写任何修改程序，只有int和raw编码的字符串对象有这些程序，所以embstr编码的对象是只读，因此发生修改的话会从embstr变成raw。 发生修改的源码中应该是将原来的ptr指向的数据结构内存释放掉后，重新指向新创建的对象。 8.2.2 字符串命令的实现所有命令都是针对字符串对象的。 命令 int 编码的实现方法 embstr 编码的实现方法 raw 编码的实现方法 SET 使用 int 编码保存值。 使用 embstr 编码保存值。 使用 raw 编码保存值。 GET 拷贝对象所保存的整数值， 将这个拷贝转换成字符串值， 然后向客户端返回这个字符串值。 直接向客户端返回字符串值。 直接向客户端返回字符串值。 APPEND 将对象转换成 raw 编码， 然后按 raw编码的方式执行此操作。 将对象转换成 raw 编码， 然后按 raw编码的方式执行此操作。 调用 sdscatlen 函数， 将给定字符串追加到现有字符串的末尾。 INCRBYFLOAT 取出整数值并将其转换成 longdouble 类型的浮点数， 对这个浮点数进行加法计算， 然后将得出的浮点数结果保存起来。 取出字符串值并尝试将其转换成long double 类型的浮点数， 对这个浮点数进行加法计算， 然后将得出的浮点数结果保存起来。 如果字符串值不能被转换成浮点数， 那么向客户端返回一个错误。 取出字符串值并尝试将其转换成 longdouble 类型的浮点数， 对这个浮点数进行加法计算， 然后将得出的浮点数结果保存起来。 如果字符串值不能被转换成浮点数， 那么向客户端返回一个错误。 INCRBY 对整数值进行加法计算， 得出的计算结果会作为整数被保存起来。 embstr 编码不能执行此命令， 向客户端返回一个错误。 raw 编码不能执行此命令， 向客户端返回一个错误。 DECRBY 对整数值进行减法计算， 得出的计算结果会作为整数被保存起来。 embstr 编码不能执行此命令， 向客户端返回一个错误。 raw 编码不能执行此命令， 向客户端返回一个错误。 STRLEN 拷贝对象所保存的整数值， 将这个拷贝转换成字符串值， 计算并返回这个字符串值的长度。 调用 sdslen 函数， 返回字符串的长度。 调用 sdslen 函数， 返回字符串的长度。 SETRANGE 将对象转换成 raw 编码， 然后按 raw编码的方式执行此命令。 将对象转换成 raw 编码， 然后按 raw编码的方式执行此命令。 将字符串特定索引上的值设置为给定的字符。 GETRANGE 拷贝对象所保存的整数值， 将这个拷贝转换成字符串值， 然后取出并返回字符串指定索引上的字符。 直接取出并返回字符串指定索引上的字符。 直接取出并返回字符串指定索引上的字符。 8.8 内存回收Redis通过跟踪对象的引用计数信息，在适当的时候自动释放对象并进行内存回收。 计数信息由 redisObject 结构的 refcount 属性记录 在创建一个新对象时， 引用计数的值会被初始化为 1 ； 当对象被一个新程序使用时， 它的引用计数值会被增一； 当对象不再被一个程序使用时， 它的引用计数值会被减一； 当对象的引用计数值变为 0 时， 对象所占用的内存会被释放。 对应的API： 函数 作用 incrRefCount 将对象的引用计数值增一。 decrRefCount 将对象的引用计数值减一， 当对象的引用计数值等于 0 时， 释放对象。 resetRefCount 将对象的引用计数值设置为 0 ， 但并不释放对象， 这个函数通常在需要重新设置对象的引用计数值时使用。 对象生命周期可以划分为创建对象、操作对象、释放对象三个阶段 一个字符串对象从创建到释放的整个过程： 12345678// 创建一个字符串对象 s ，对象的引用计数为 1robj *s = createStringObject(...)// 对象 s 执行各种操作 ...// 将对象 s 的引用计数减一，使得对象的引用计数变为 0// 导致对象 s 被释放decrRefCount(s) 是不是通过计算指向对象这块内存的指针数量来实现的？ 8.9 对象共享对于整数值的字符串对象（int编码），在新创建一个字符串对象的时候如果有这个值的字符串对象存在，就不再为新键创建字符串对象，而是将这个新键指向之前已经存在了的字符串对象。然后将这个字符串对象的引用+1。主要目的是节约内存。 Redis初始化服务器的时候创建一万个字符串对象， 这些对象包含了从 0 到 9999 的所有整数值， 当服务器需要用到值为 0到 9999 的字符串对象时， 服务器就会使用这些共享对象， 而不是新创建对象。 创建共享字符串对象的数量可以通过修改 redis.h/REDIS_SHARED_INTEGERS 常量来修改。 为什么 Redis 不共享包含字符串的对象？ 当服务器考虑将一个共享对象设置为键的值对象时， 程序需要先检查给定的共享对象和键想创建的目标对象是否完全相同， 只有在共享对象和目标对象完全相同的情况下， 程序才会将共享对象用作键的值对象， 而一个共享对象保存的值越复杂， 验证共享对象和目标对象是否相同所需的复杂度就会越高， 消耗的 CPU 时间也会越多： 如果共享对象是保存整数值的字符串对象， 那么验证操作的复杂度为 O(1) ； 如果共享对象是保存字符串值的字符串对象， 那么验证操作的复杂度为 O(N) ； 如果共享对象是包含了多个值（或者对象的）对象， 比如列表对象或者哈希对象， 那么验证操作的复杂度将会是 O(N^2) 。 因此， 尽管共享更复杂的对象可以节约更多的内存， 但受到 CPU 时间的限制， Redis 只对包含整数值的字符串对象进行共享。 （时刻在空间与时间上做权衡） 8.9 对象的空转时长lru 属性， 该属性记录了对象最后一次被命令程序访问的时间。 OBJECT IDLETIME 命令可以打印出给定键的空转时长， 这一空转时长就是通过将当前时间减去键的值对象的 lru 时间计算得出的。 OBJECT IDLETIME 命令的实现是特殊的， 这个命令在访问键的值对象时， 不会修改值对象的 lru 属性。 lru的主要作用就是配合maxmemory选项，淘汰不常用的键值对。 如果服务器打开了 maxmemory 选项， 并且服务器用于回收内存的算法为 volatile-lru 或者 allkeys-lru ， 那么当服务器占用的内存数超过了 maxmemory 选项所设置的上限值时， 空转时长较高的那部分键会优先被服务器释放， 从而回收内存。 疑惑 为什么在一块连续的内存里面可以更好地利用缓存带来的优势？ 引用计数的程序怎么定义？是指线程吗？ 引用计数的具体实现？ 对象共享的时候怎么去判断存不存在已经创建了这个整数值的对象？对整个数据库遍历吗？]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>redis</tag>
        <tag>object</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[剑指offer 读书笔记——第2章]]></title>
    <url>%2F2019%2F03%2F27%2F2019-03-27-%E5%89%91%E6%8C%87offer-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%E2%80%94%E2%80%94%E7%AC%AC2%E7%AB%A0%2F</url>
    <content type="text"><![CDATA[剑指offer 读书笔记——第2章感觉自己的代码能力还在很弱，所以又第二遍仔细的阅读剑指offer了 第二章 面试需要的基础知识 面试题1 赋值运算函数所谓赋值运算函数就是对=这个操作符进行重载，从而使等号能够直接用于两个实例之间的赋值。这个C++课上学过，不过现在忘完了，只记得学过。 经典解法需要考虑的点 返回值的类型声明为该类型的引用，在函数结束前返回实例自身的引用(*this)。只有返回一个引用，才可以连续赋值。object1=object2=object3就是连续赋值。赋值采用右结合律，从最右边开始计算。不然的话当首先执行完object2=object3 后，object2 虽然自己的成员已经得到了更改，但是它不能再作为object1=object2 这个等号的右值，因为在前一个=的执行中，它没有获得返回值。而返回对象的话，就需要重新执行新建一个对象和销毁对象的构造与析构操作，增加不必要开销，降低赋值函数的效率。 传入的参数申明为常量引用 释放实例自身已有的内存 判断传入参数是否和当前的实例相同，相同的话不进行赋值操作，直接返回实例。 代码：初级版 12345678910111213CMyString&amp; CMyString::operator = (const CMyString&amp; str)&#123; if(this == &amp;str) return *this; delete []m_pData; m_pData = nullptr; m_pData = new char[strlen(str.m_pData) + 1]; //给strcpy复制的字符串申请空间 strcpy(m_pData, str.m_pData); return *this;&#125; 代码：高级版 1234567891011CMyString&amp; CMyString::operator = (const CMyString&amp; str)&#123; if(this != &amp;str)&#123; CMyString strTemp(str); // 新建一个实例 char *pTemp=strTemp.m_pData; // 新建一个临时指针保存数据 strTemp.m_pData = m_pData; // 交换 m_pData = pTemp; &#125; return *this;&#125; 初级版在使用new分配内存的时候，已经把原来的数据给清楚了（delete []m_pData;）,这时在新分配内存的时候，如果内存不足会导致new char抛出异常，使得m_pData 变成一个空指针，这样很容易导致程序崩溃。因为在抛出异常之后，原来的CMyString实例因为数据被delete了，所以不再保持有效的状态，违背了异常安全性的原则。 （可以先将原来的数据备份，等new 成功了，再将原来的数据delete给释放掉） 代码思路：新建一个实例，新建一个临时指针从而用于数据交换。 123456tmp tmp^ || str&lt;--this 先将str的值备份到tmp中，然后将str的值更新为this的值，然后在把this的值更新为tmp的值两个数据的交换必然需要新建第三个变量来存放其中一个变量的值。 之所以需要新建一个实例是因为实例是个临时变量，所以完成操作后会自动释放掉他的数据，也就是原来的数据。 指针与引用的异同 常量指针与常量引用。 对于引用只有两种描述： 1234// 对常量类型的引用 const type &amp;ref = type a;//对变量类型的引用type &amp;ref = type a; 对常量类型的引用 实际上既可以对常量类型引用，也可以对变量类型引用，但是不能通过引用来修改它引用的对象。 对于指针的修饰有4种： 1234567891011121314151617// 普通的指针 poi is a pointer point to a type ，//指针的值（指向的地址，可以改变），被指向的变量的值也可以改变type *poi;//常量指针 poi is a const pointer point to a type //指针的值（指向的地址）不能改变，被指向的变量的值可以改变type *const poi;// poi is a pointer point to a const type//指针的值（指向的地址）可以改变，所以指针可以指向其他变量，//被指向的变量的值不可以改变，所以指针不能修改指向的变量的值，const type *poi;// poi is a const pointer point to a const type// 指针的值（指向的地址）不能改变，所以指针不能指向其他变量，//被指向的变量的不可以改变，所以指针不能修改指向的变量的值const type *const poi; 以* &amp;作为分割符进行读取，const作为前缀修饰的对象,对象存储的值不变。 对于指向const type 的指针或者引用而言，指向的（引用的）变量类型不一定是常量，但是无法通过指针或者引用来修改其指向的（引用的）变量的值。《C++primer》中所说：所谓指向常量的指针或引用，不过是指针自以为自己指向了一个常量，所以自觉地不去改变所指对象的值。 疑惑 为什么申明的返回值是引用，而返回的却是指针？ 引用是地址的别名,但是不分配内存空间。 CMyString &amp;A= *this 这里this是指向CMyString这个类的实例的地址，而A是CMyString的一个实例的引用，是引用就需要与这个实例的内存地址相关联，所以可以传入 this ，也就是实例的地址。 本来 =号用于赋值的时候，左值是地址，右值是变量地址上的数据也就是变量的值，但是引用的=号的右值是变量的地址。所以可以传入地址，也就是指针。 传入的参数是个常量引用，为什么不使用常量指针： const CMyString *str 虽然const CMyString *str 和congst CMyString &amp;str 都不能去修改实参的值了，但是引用不是对象，是不分配内存的啊，使用指针的话，肯定会占用内存，然后不用的时候销毁内存，所以效率会降低。而且引用是一定不会空的，所以不用考虑所指的对象是否为空。（提升效率的关键，可以不申请内存就不申请内存，因为不管是自己去释放，还是系统自动回收，分配和回收都会带来效率的下降。所以能用指针就用指针，能用引用就用引用，最坏的情况才是值拷贝。）（ 对象是指一块能存储数据并具有某种类型的内存空间）]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>coding</tag>
        <tag>c++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis 设计与实现读书笔记——第四章 字典]]></title>
    <url>%2F2019%2F03%2F27%2F2019-03-27-Redis-%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B0%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%E2%80%94%E2%80%94%E7%AC%AC%E5%9B%9B%E7%AB%A0-%E5%AD%97%E5%85%B8%2F</url>
    <content type="text"><![CDATA[Redis 设计与实现读书笔记——第四章 字典字典在Redis中应用很广泛，Redis的数据库就是用字典作为底层实现的，对数据库的增删改查操作也是构建在对字典的操作之上的。 简介作用： 数据库底层实现 哈希键底层实现 哈希键包含的键值对比较多，或者键值对中的元素都是比较长的字符串时，使用字典来实现。 其他功能 4.1 字典的实现字典使用哈希表实现，一个哈希表里面可以有多个哈希表节点，一个哈希表节点就保存了字典中的一个键值对。（python的dict也是使用哈希表实现的）。 哈希的本质就是预留内存空间，将需要存储的元素计算索引值(通过哈希函数)来确定对应的存储位置。当需要访问的时候可以通过哈希函数直接获得对应的地址。（编译器将变量名与地址做了映射，变量名是地址的别名，哈希则是将键与地址做了映射（通过哈希函数），大大提高了访问的效率。访问任何元素都是O（1），感觉是两个层面的映射，有点相似的感觉）。 4.1.1 哈希表Redis使用的哈希表由dict.h/dictht 结构定义。 1234567891011typedef struct dictht &#123; //哈希表数组 dictEntry **table; // 哈希表大小 unsigned long size; //哈希表大小掩码，用于计算索引值 //总是等于size-1 unsigned long sizemask; //该哈希表已有节点的数量 unsigned long used;&#125; dictht; typedef Oldname newname 所以这里是typedef struct dictht dictht 将struct dictht 取了个别名dictht。 dictEntry **table; 书上解释的是table是数组，但是最直接的说法是table是一个指向（指向dictEntry类型的指针）的指针，是指向指针的指针。 数组获得内存是连续的，而指针不是，所以书中说是table数组，应该是分配内存的时候给指针分配了连续的内存，但是代码没找到。 关于指针和数组的异同《C专家编程》一书有讲解（第四章、第九章、第十章）。 主要的不同：指针存放的是地址，所以需要经过两次取地址的内容。（取指针的地址中的数据（变量的地址），取变量地址的数据）。而数组是直接存储数组的首元素的数据，所以只用一次取地址中的数据 数组与指针相同 表达式中的数组名就是指针 C语言把数组下标作为指针的偏移量。a是数组，a[6]就是首地址偏移6。b是指针，b[6]也是指针存储的地址向后偏移6. 作为函数参数的数组名等同于指针。只是把首地址传入给了参数，并没有把数组所有的内存区域都传入。所以传入数组，就是传入指针。 sizemask和哈希值一起决定一个键应该被放到table数组的那个索引上面。 4.1.2 哈希表节点使用dictEntry结构体表示节点，每一个dictEntry结构都保存着一个键值对。 12345678910111213typedef struct dictEntry &#123; // 键 void *key; // 值 union &#123; void *val; uint64_t u64; int64_t s64; double d; &#125; v; //指向下一个哈希表节点 struct dictEntry *next;&#125; dictEntry; key指向键值对中的键，而v则保存键值对中的值，值可以是一个指针，或者uint64_t整数，或者有符号的int64_t整数,或者是double类型（double也占8byte无论32还是64位）。 union 是c中的共用体（联合体），和结构体非常类似。和结构体的区别是 结构体的各个成员会占用不同的内存，互相之间没有影响；而共用体的所有成员占用同一段内存，修改一个成员会影响其余所有成员。 结构体占用的内存大于等于所有成员占用的内存的总和（成员之间可能会存在缝隙），共用体占用的内存等于最长的成员占用的内存。共用体使用了内存覆盖技术，同一时刻只能保存一个成员的值，如果对新的成员赋值，就会把原来成员的值覆盖掉。 所以这里面v占用8byte内存，但是属性却可以有4中。 next指针可以将多个哈希值相同的键值对链接在一起，用来解决哈希键冲突(索引相同)的问题。链式的方法。 4.1.3 字典Redis中字典由dict.h/dict 结构体表示。 12345678910111213typedef struct dict &#123; //类型特定函数 dictType *type; // 私有数据 void *privdata; // 哈希表 dictht ht[2]; //rehash 索引 //当rehash不在进行是值为-1。用来记录是否在rehash long rehashidx; /* rehashing not in progress if rehashidx == -1 */ //当前迭代的个数 unsigned long iterators; /* number of iterators currently running */&#125; dict; type 和private属性是针对不同类型的键值对（redis支持5中数据类型），为创建多态字典而设置的。 type指向dictType结构，dictType结构保存了一簇用于操作特定类型键值对的函数，Redis为不同用途的字典设置了不同的类型的特定函数。（多态的表现。） privadata属性保存了需要传给哪些类型特点函数的可选参数。 1234567891011121314typedef struct dictType &#123; // 计算哈希值的函数 uint64_t (*hashFunction)(const void *key); // 复制键的函数 void *(*keyDup)(void *privdata, const void *key); // 复制值的函数 void *(*valDup)(void *privdata, const void *obj); // 对比键的函数 int (*keyCompare)(void *privdata, const void *key1, const void *key2); // 销毁键的函数 void (*keyDestructor)(void *privdata, void *key); // 销毁值的函数 void (*valDestructor)(void *privdata, void *obj);&#125; dictType; ht是长度为2的数组，而数组的元素就是哈希表dictht。一般情况只会使用ht[0],ht[1]只会在ht[0]空间不够的时候进行rehash的时候使用。 rehashidx 用来标识是否在 rehash，没有的话值为-1,有的话rehasidx用来记录rehash的进度。 4.2 哈希算法添加一个新的键值对的时候， 1. 需要先根据键值使用hash函数计算哈希值 2. 哈希值和sizemask并运算求得索引值 3. 再根据索引值将包含键值对的哈希表节点放到哈希表数组table上的对应索引值上。 Redis 计算哈希值和索引值的方法为 123456# 使用字典设置的哈希函数，计算键 key 的哈希值hash = dict-&gt;type-&gt;hashFunction(key);# 使用哈希表的 sizemask 属性和哈希值，计算出索引值# 根据情况不同， ht[x] 可以是 ht[0] 或者 ht[1]index = hash &amp; dict-&gt;ht[x].sizemask; 哈希值用hashFunction计算，index用hash值和sizemask进行并操作。 对应在源码中为： 12345//dict.h 中：#define dictHashKey(d, key) (d)-&gt;type-&gt;hashFunction(key) //计算哈希值//dict.c 中idx = hash &amp; d-&gt;ht[table].sizemask;h = dictHashKey(d, de-&gt;key) &amp; d-&gt;ht[1].sizemask; 插入一个键值对&lt;k0,v0&gt;到字典中的过程为： 先使用语句 1hash = dict-&gt;type-&gt;hashFunction(k0); 计算键 k0 的哈希值。 假设计算得出的哈希值为 8 ， 那么程序会继续使用语句 1index = hash &amp; dict-&gt;ht[0].sizemask = 8 &amp; 3 = 0; 计算出键 k0 的索引值 0 ， 这表示包含键值对 k0 和 v0 的节点应该被放置到哈希表数组的索引 0 位置上。 当字典被用作数据库的底层实现， 或者哈希键的底层实现时， Redis 使用 MurmurHash2 算法来计算键的哈希值。算法的优点 即使输入的键是有规律的， 算法仍能给出一个很好的随机分布性， 并且算法的计算速度也非常快。 MurmurHash 算法目前的最新版本为 MurmurHash3 ， 而 Redis 使用的是 MurmurHash2 ， 关于 MurmurHash 算法的更多信息可以参考该算法的主页： http://code.google.com/p/smhasher/ 。 暂时没有找到hashFunction的源码。 4.3 键冲突两个以上的键分配到了同一个索引就产生了冲突。 使用链地址法解决，相同索引上面的节点可以用next指针来链接，这样同一个索引就可以存放多个哈希表节点了。 哈希表节点没有指向链表链尾的节点，所以不能迅速的知道哪个节点是尾节点，（只能通过遍历才能找到指向null的尾节点O(N)）,所以为了速度考虑总是将新节点插入到最前面（dictht-&gt;table指针指向的第一个节点就是最前面的节点。） 直接使用书上的图： 还未发生键冲突 键冲突发生后：新键值对&lt;k2,v2&gt; 插入到&lt;k1,v1&gt;前面。 4.4 rehash哈希表保存的键值对会增多或者减少，需要让负载因子（负载因子(load factor)，它用来衡量哈希表的 空/满 程度，一定程度上也可以体现查询的效率）维持在合理的范围，所以哈希节点太多的时候需要扩容（不然冲突太多，降低效率），这些哈希表的空间动态扩容或者缩容通过rehash操作来实现。 步骤为： 为ht[1]分配空间 扩容时ht[1].size = 大于等于ht[0].used*2的第一个2^n。 收缩时ht[1].size = 大于等于ht[0].used的第一个2^n。 迁移：将ht[0]上面的哈希节点重新计算哈希值与索引值并放到ht[1]哈希表上面。 迁移完成后释放ht[0],把ht[1]设置成ht[0],并在ht[1]新创建一个空白哈希表，等待下一次rehash。 注意：不管是扩容还是收缩，新分配的空间都会比原来用到的(used)大。设置ht[1]为ht[0] 的时候只需要简单的将原来ht[0]上面的指针指向ht[1]就好，但是需要把原来指向的哈希表的内存给释放掉。（指针是真的强，每次指针变换指向的地址的时候，都需要考虑下之前指向的地址是否还需要，不需要就要释放，不然会造成内存泄漏）。ht[1]则重新新建个哈希表结构体，然后把ht[1]的指针指过来就好了。 rehash的过程图解参考书中的图讲的很详细。 假设程序要对图 4-8 所示字典的 ht[0] 进行扩展操作。 ht[0].used 当前的值为 4 ， 4 * 2 = 8 ， 而 8 （2^3）恰好是第一个大于等于 4 的 2 的 n 次方， 所以程序会将 ht[1] 哈希表的大小设置为 8 。图 4-9 展示了 ht[1] 在分配空间之后， 字典的样子： 将 ht[0] 包含的四个键值对都 rehash 到 ht[1] ， 如图 4-10 所示。 释放 ht[0] ，并将 ht[1] 设置为 ht[0] ，然后为 ht[1] 分配一个空白哈希表，如图 4-11 所示。 哈希表的扩展与收缩（源码还没找到） 当以下条件中的任意一个被满足时， 程序会自动开始对哈希表执行扩展操作： 服务器目前没有在执行 BGSAVE 命令或者 BGREWRITEAOF 命令， 并且哈希表的负载因子大于等于 1 ； 服务器目前正在执行 BGSAVE 命令或者 BGREWRITEAOF 命令， 并且哈希表的负载因子大于等于 5 ； 其中哈希表的负载因子可以通过公式得到。 12# 负载因子 = 哈希表已保存节点数量 / 哈希表大小load_factor = ht[0].used / ht[0].size 4.5 渐进式rehash考虑到redis数据库中存储的键值对很多的情况，如果一次性就rehash完，庞大的计算量可能会导致服务器性能急剧下降，甚至一段时间的停止服务，（经济学中的休克时疗法？）所以rehash这个过程需要渐进式的（软着陆）。 步骤： 为 ht[1] 分配空间， 让字典同时持有 ht[0] 和 ht[1] 两个哈希表。 在dict中维持一个索引计数器变量 rehashidx ， 并将它的值设置为 0 ， 表示 rehash 工作正式开始。 在 rehash 进行期间， 每次对字典执行添加、删除、查找或者更新操作时， 程序除了执行指定的操作以外， 还会顺带将 ht[0] 哈希表在 rehashidx 索引上的所有键值对 rehash 到 ht[1] ， 当 rehash 工作完成之后， 程序将 rehashidx 属性的值增一。 随着字典操作的不断执行， 最终在某个时间点上， ht[0] 的所有键值对都会被 rehash 至 ht[1] ， 这时程序将 rehashidx 属性的值设为 -1 ， 表示 rehash 操作已完成。 注意： rehashidx的范围是从-1到ht[0].size-1 ，也就是对应的哈希表的索引，不是之前理解的记录哈希节点的个数。 迁移的过程不是拷贝，而是哈希表存储的哈希指针重新指向哈希节点的过程（指针对地址的操作）。 rehash 键值对所需的计算工作均滩到对字典的每个添加、删除、查找和更新操作上， 从而避免了集中式 rehash 而带来的庞大计算量。 过程图解依然copy自redis设计与实现的电子书。 渐进式rehash期间的哈希表操作增删改查在两个表上操作，但是添加的新键只添加到ht[1]上，确保ht[0]最终变成空表。 4.6 字典API疑惑 为什么不直接用dictEntry *table[] 来表示，却要用指针？应该是指针更加灵活些？ 因为dict有两个哈希表，而其中有个哈希表ht[1] 是只有在rehash的时候才会使用的，因此使用指针的的话，在不需要的时候将table直接指向null就可以简单的完成释放空间的操作，如果用数组的话,在分配内存的时候，就必须要为两个dictht都分配size个byte的内存存储空间，当rehash的时候size会变化，结构体中的数组就需要重新分配内存空间，而结构体的内存是相邻连续的，所以这时候要变化空间，只能重新再给这个结构体分配空间，这样效率肯定就很低了。所以使用指针的原因就是rehash的时候数组的大小会变化，如果用数组来记录就很麻烦和效率低了。 所以在dict中可以使用数组来存储dictht,因为ht这个数组是不会变化的。 既然在rehash过程中会有增删改查的操作，那么这些操作是在哪个哈希表上进行的呢？ 两个哈希表上面都会进行，但是增加的键值对会在ht[1] 上，不然ht[0]在减少的时候又新增键值对，不是在做无用之功吗。 参考http://redisbook.com/preview/dict/hash_algorithm.html https://blog.csdn.net/yangbodong22011/article/details/78467583]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>redis</tag>
        <tag>dict</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用Travis-CI自动部署博客]]></title>
    <url>%2F2019%2F03%2F26%2F2019-03-26-%E4%BD%BF%E7%94%A8Travis-CI%E8%87%AA%E5%8A%A8%E9%83%A8%E7%BD%B2%E5%8D%9A%E5%AE%A2%2F</url>
    <content type="text"><![CDATA[使用Travis-CI自动部署博客因为在github上面存储的是编译好的html代码，不是hexo博客中的博客源文件，所以如果没有备份源文件的话，丢失了源文件（包括md,一堆配置文件）后就不能继续更新博客了，而且也不能多端部署Hexo。网上看到可以使用Travis-CI来自动部署，同时解决了博客源文件的备份问题。 新建hexo分支来保存源文件新建分支直接在对应的github.io项目上的branch 按钮处点击新建分支 hexo。 官方文档https://help.github.com/en/articles/setting-the-default-branch 12# 克隆项目到本地&gt; git clone https://github.com/BraveY/BraveY.github.io.git 设置默认分支参照官方文档设置https://help.github.com/en/articles/setting-the-default-branch 修改推送hexo分支现将原来的文件BraveY.github.io 修改为BraveY.github.io.bak 避免拷贝的时候出现文件夹重名，同时将原来的hexo 目录blog文件也修改为blog.bak 直接克隆到 本地 12# 克隆项目到本地&gt; git clone https://github.com/BraveY/BraveY.github.io.git 这时拷贝的项目已经是hexo分支下面的，因为之前是设置了hexo分支作为默认分支的。 将克隆的BraveY.github.io文件夹重命名为blog 在克隆的文件夹里面删除除了.git的所有文件 注意 ：因为主题的next也是个git仓库，所以需要先把next目录下的.git删除 然后先把theme/next 目录下的.git 给删除掉，不然的话next这个主题本来就是个git仓库，里面的个性化配置是无法上传到自己的项目中的，而且以后也无法克隆。 从blog.bak文件中把所有hexo的源码文件拷过来。 在博客目录下初始化git仓库并将所有文件提交。 添加到远程仓库 123git add . git commit -m&quot;description&quot;git push origin 现在hexo分支已经是存放了hexo的源文件了。 设置Travis CI主要参考下面的三个博客， Travis CI 官网登陆使用github账号登陆Travis CI官网 ，选择博客项目启动。然后进行设置。 没有文章中说的Build only if .travis.yml is present 选项，但好像没有影响，采用默认的选项。 github生成Access Token参考博客，不赘述。 Travis CI配置travis.yml在blog根目录下设置travis配置文件。 .travis.yml 文件的配置为： 123456789101112131415161718192021222324252627282930313233343536language: node_js # 设置语言node_js: stable # 设置相应版本cache: apt: true directories: - node_modules # 缓存不经常更改的内容before_install:- export TZ='Asia/Shanghai' # 更改时区install:- npm installscript:- hexo clean- hexo g after_script:- git clone https://$&#123;GH_REF&#125; .deploy_git- cd .deploy_git- git checkout master- cd ../- mv .deploy_git/.git/ ./public/- cd ./public- git config user.name "BraveY"- git config user.email "lsz_yky@163.com"- git add .- git commit -m "Travis CI Auto Builder at `date +"%Y-%m-%d %H:%M"`"- git push --force --quiet "https://$&#123;github_blog@$&#123;GH_REF&#125;" master:masterbranches: only: - hexoenv: global: - GH_REF: github.com/BraveY/BraveY.github.io.gitnotifications: email: - lsz_yky@163.com on_success: change on_failure: always 新增文章到_posts增减文章后，使用git push 命令即可，自动部署。 可以看到 Travis CI 上面构建的一系列输出，但是博客并没有更新，而且github上的master分支也没有更改过。查看Travis CI 上的输出信息，发现在执行 git push --force --quiet &quot;https://${github_blog@${GH_REF}&quot; master:master 这句后报错： 12/home/travis/.travis/functions: eval: line 104: unexpected EOF while looking for matching `&quot;&apos;/home/travis/.travis/functions: eval: line 105: syntax error: unexpected end of file 然后发现${github_blog@${GH_REF} 这句花括号没有对齐匹配，无语。加上漏掉的右边花括号} 重新执行操作。一切正常。 博客更新操作后面就不用自己hexo g -d 了 在_posts目录下增加文章后 123git add .git commit -m&quot;&quot;git push origin 感觉可以写个脚本 命名为git_script.ps1 以后直接用powershell运行这个脚本就可以了。 1234git add .$date = get-date -uformat &quot;%Y-%m-%d %H:%M:%S&quot;git commit -m&quot;new post $date&quot;git push origin 参考https://www.itfanr.cc/2017/08/09/using-travis-ci-automatic-deploy-hexo-blogs/ http://www.dxjia.cn/2016/01/27/hexo-write-everywhere/ http://www.yanglangjing.com/2018/08/28/travis_ci_auto_deploy_hexo_to_vps/]]></content>
      <categories>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
        <tag>Travis-CI</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis源码阅读——SDS]]></title>
    <url>%2F2019%2F03%2F22%2FRedis%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%E2%80%94%E2%80%94SDS%2F2019-03-22-Redis%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%E2%80%94%E2%80%94SDS%2F</url>
    <content type="text"><![CDATA[Redis源码阅读——SDS参考Redis设计与实现 以及网上博客阅读Redis源码。 SDS相关知识点见读书笔记。 创建和销毁为了能够对sds进行相关API的测试，因此把sds模块单独提出来。阅读Redis的Makefile发现，编译sds模块需要的源文件包括sds.c, sds.h zmalloc.c 123test-sds: sds.c sds.h $(REDIS_CC) sds.c zmalloc.c -DSDS_TEST_MAIN $(FINAL_LIBS) -o /tmp/sds_test /tmp/sds_test 但是实际编译后会发现会报很多函数未定义的错。原因是redis源码里面sds的内存分配、释放、重分配这些函数是封装成zmalloc,zfee这些函数的，只单纯的把zmalloc.c提取出来是远远不够的。后面发现redis的作者已经把sds给单独提出来了。包括三个源文件sds.c,sds.h,sdsalloc.h 因此执行如下操作即可单独把redis的sds模块提取出来。 提取sds模块 新建redis_sds测试目录 选择合适的目录下新建 mkdir redis_sds 复制源文件至redis_sds目录下 在redis源码的src目录下执行： cp sds.c ~/redis_sds/ cp sds.h ~/redis_sds/ cp sdsalloc.h ~/redis_sds/ 修改sdsalloc.h 复制过来的sdsalloc.h 将sds模块的内存函数封装为使用zmalloc函数。为了简化处理直接使用libc的malloc函数来进行内存管理，同时将zmalloc.h给注释掉。 1234//#include "zmalloc.h"#define s_malloc malloc#define s_realloc realloc#define s_free free 新建主函数 新建主函数sds_test.c 1234567891011121314#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include "sds.c"//#include "sds.h"int main(int argc, char *argv[]) &#123; sds s = sdsnew("Hello World!"); printf("Length:%d, Type:%d\n", sdslen(s), sdsReqType(sdslen(s))); s = sdscat(s, "The length of this sentence is greater than 32 bytes"); printf("Length:%d, Type:%d\n", sdslen(s), sdsReqType(sdslen(s))); sdsfree(s); return 0;&#125; 直接include sds.c 即可，因为如果#include “sds.h” 的话，sdsReqType这个函数并没有在sds.h里面声明，而且因为sdsReqType的申明是： static inline char sdsReqType(size_t string_size) { 有static限制所以不能在sds.h中先声明，所以为了简单就直接#include 了sds.c了 编译 为了方便重复编译，所以写了个简单的Makefile。 12test : sds_test.c sds.h sds.c sdsalloc.h gcc -o sdstest sds_test.c 只需要编译sds_test.c 即可。因为sds_test.c 里面是直接#include sds.c 了所以再 gcc -o sdstest sds_test.c sds.c 会将sds.c 里面的函数重复编译两次，造成Multiple definition 问题。 之后只需要执行make命令就可以生成可执行文件sdstest。 执行后输出为： 123./sdstest Length:12, Type:0Length:64, Type:1 sds的创建通过sdsnew 来创建了一个sds。sdsnew源码为： 123456/* Create a new sds string starting from a null terminated C string. */sds sdsnew(const char *init) &#123; //使用？条件判断符来简化if语句对NULL的判断，直接使用strlen来返回字符指针的长度。 size_t initlen = (init == NULL) ? 0 : strlen(init); return sdsnewlen(init, initlen);&#125; 需要注意的是字符数组和字符指针是有区别的：字符指针的数据是存放在进程的虚拟地址空间的程序代码和数据段，是只读的不能修改。字符数组存放的字符串数据是存放在用户栈的，是可以更改的。且字符指针的数据没有”\0”这个结束符。 参考博客讲的很好：https://blog.csdn.net/on_1y/article/details/13030439 sdsnew 通过把字符串长度和字符串传递给sdsnewlen，来完成创建。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071/* Create a new sds string with the content specified by the 'init' pointer * and 'initlen'. * If NULL is used for 'init' the string is initialized with zero bytes. * * The string is always null-termined (all the sds strings are, always) so * even if you create an sds string with: * * mystring = n("abc",3); * * You can print the string with printf() as there is an implicit \0 at the * end of the string. However the string is binary safe and can contain * \0 characters in the middle, as the length is stored in the sds header. */sds sdsnewlen(const void *init, size_t initlen) &#123; void *sh; sds s; char type = sdsReqType(initlen); //返回字符串对应的type /* Empty strings are usually created in order to append. Use type 8 * since type 5 is not good at this. */ /* 空字符串使用sdshdr8来存储，而不是sdshdr5,（虽然长度小于32），因为sdshdr5不适合扩容。 */ if (type == SDS_TYPE_5 &amp;&amp; initlen == 0) type = SDS_TYPE_8; int hdrlen = sdsHdrSize(type); // 返回对应类型的sdsheader长度。 unsigned char *fp; /* flags pointer. */ sh = s_malloc(hdrlen+initlen+1); // 申请头部+字符串+NULL的大小。(单位为byte) if (!init) memset(sh, 0, hdrlen+initlen+1); // 将sh后面对应大小的字节全部置为0； if (sh == NULL) return NULL; s = (char*)sh+hdrlen; //s指针指向字符串的首字节。 fp = ((unsigned char*)s)-1; // fp指针指向flag switch(type) &#123; // 初始化sdshdr case SDS_TYPE_5: &#123; *fp = type | (initlen &lt;&lt; SDS_TYPE_BITS);// 设置flag这个字节的具体值 break; &#125; case SDS_TYPE_8: &#123; SDS_HDR_VAR(8,s); // 获取header指针sh sh-&gt;len = initlen; //header中len的初始 sh-&gt;alloc = initlen; //header 中alloc的初试 *fp = type; //flag 的初始。 break; &#125; case SDS_TYPE_16: &#123; SDS_HDR_VAR(16,s); sh-&gt;len = initlen; sh-&gt;alloc = initlen; *fp = type; break; &#125; case SDS_TYPE_32: &#123; SDS_HDR_VAR(32,s); sh-&gt;len = initlen; sh-&gt;alloc = initlen; *fp = type; break; &#125; case SDS_TYPE_64: &#123; SDS_HDR_VAR(64,s); sh-&gt;len = initlen; sh-&gt;alloc = initlen; *fp = type; break; &#125; &#125; if (initlen &amp;&amp; init) memcpy(s, init, initlen); // 将字符串拷贝到s(也就是buf数组) s[initlen] = '\0'; //在字符串后面添加终止符 return s;&#125; char type = sdsReqType(initlen); 获取sds类型，源码分析在读书笔记里面有记录。源码为 12345678910111213static inline char sdsReqType(size_t string_size) &#123; if (string_size &lt; 1&lt;&lt;5) // string_size &lt; 2^5 return SDS_TYPE_5; if (string_size &lt; 1&lt;&lt;8) //string_size &lt; 2^8 return SDS_TYPE_8; if (string_size &lt; 1&lt;&lt;16) //string_size &lt; 2^16 return SDS_TYPE_16;#if (LONG_MAX == LLONG_MAX) if (string_size &lt; 1ll&lt;&lt;32) //string_size &lt; 2^32 return SDS_TYPE_32;#endif return SDS_TYPE_64; &#125; 采用左移来计算对应多少位的范围，而不是用2^5 这样的乘法。直接移位比使用幂来计算快很多。 1&lt;&lt;5 计算出来就是2^5 次方。1是int型，4byte32位。最低8bit位的二进制为：00000001 左移5位后变成了：00100000 对应的十进制既是32。 计算n个bit位的最大值：(1&lt;&lt;n) -1 但是需要注意位数不够的情况。因为1是int型，只有32个bit。所以在左移32个bit时，需要使用long long int型。用1ll来表示，此时1ll为64个bit。 还得考虑机器是否为64位机器，在32位机器上LONG_MAX = 2147483647L，64位机器上LONG_MAX = 9223372036854775807L 。不论32位机器还是64位机器上 LLONG_MAX 都是9223372036854775807L 。所以当LONG_MAX == LLONG_MAX 说明字长为64bit。加上条件编译，说明在32位机器上不使用sdshdr32而直接跳到了sdshdr64，仅仅在64位机器上使用sdshdr32。原因是什么？还没想通 123456789101112131415static inline int sdsHdrSize(char type) &#123; switch(type&amp;SDS_TYPE_MASK) &#123; case SDS_TYPE_5: return sizeof(struct sdshdr5); case SDS_TYPE_8: return sizeof(struct sdshdr8); case SDS_TYPE_16: return sizeof(struct sdshdr16); case SDS_TYPE_32: return sizeof(struct sdshdr32); case SDS_TYPE_64: return sizeof(struct sdshdr64); &#125; return 0;&#125; 因为struct里面的buf数组是柔性数组，计算结构体的大小的时候不会计算在内。 memset(sh, 0, hdrlen+initlen+1); memset函数会将sh中当前位置后面的hdrlen+initlen+1个字节全部置于0。 注意sh指向的是hdrlen+initlen+1 个字节的首个字节。（sh指针存储的地址就是首个字节的地址。） memset源码为：https://github.com/gcc-mirror/gcc/blob/master/libgcc/memset.c 1234567891011/* Public domain. */#include &lt;stddef.h&gt;void *memset (void *dest, int val, size_t len)&#123; unsigned char *ptr = dest; // 用char来限定每次指针+1只移动一个字节。 while (len-- &gt; 0) *ptr++ = val; return dest;&#125; 假设hdrlen+initlen+1 为8 ，经过memset后，从sh首字节开始共有8个字节都被置为0。 指针的类型时用来确定指针需要从首地址寻址（偏移）多少个字节。比如int * 指针说明指针存储的地址朝后面偏移3个字节才是这个int类型的所有数据。即指针存储的地址时起点，而终点是由类型来确定的。此外，类型也是指针加减的步长，比如char类型的步长就是1byte，而uint_16类型的指针步长就是2byte。 随后用switch语句对不同类型的sdshdr设置初始值。 首先是sdshdr5 *fp = type | (initlen &lt;&lt; SDS_TYPE_BITS) 使用移位和或操作的方式来对8个bit位赋值。(不得不感慨这些操作真的是太巧妙了) 假设initlen为3。则initlen的二进制为0000 0011（应该是8byte（64位机器）或者4byte（32位机器），为了简单用1byte的二进制表示）而SDS_TYPE_BITS 为3。所以先将initlen 左移3个bit 变成0000 0001 1000(共有8byte或者4byte)。再与type进行或运算。type为0000 0000 进行或运算后，得到的内容是8bit的，因为type是char类型，即0001 1000 。 其他sdshdr类型的设置都差不多，详解下sdshdr8. SDS_HDR_VAR(8,s) SDS_HDR_VAR 是个宏定义的函数 #define SDS_HDR_VAR(T,s) struct sdshdr##T *sh = (void*)((s)-(sizeof(struct sdshdr##T))); 采用宏定义函数的好处是 能够减少额外的开销 因为如果写成普通函数的话，函数的调用会在用户栈开辟空间，形参压栈，返回时还需要释放栈，可想而知的开销。使用宏定义函数则在代码规模和速度方面都比函数更胜一筹。宏定义的本质就是替换，所以在使用宏定义函数的地方，执行的时候相当于是在直接执行struct sdshdr##T *sh = (void*)((s)-(sizeof(struct sdshdr##T))) 这句代码 函数的参数必须被声明为一种特定的类型，所以它只能在类型合适的表达式上使用。而宏定义则可以用于整形、长整形、单浮点型、双浮点型以及其他任何可以用“&gt;”操作符比较值大小的类型，也就是说，宏是与类型无关的。（有点C++模版类的感觉） 宏定义函数中的## 是（token-pasting）符号连接操作符 直接将形参T链接到sdshdr上面。也就是sdshdrT。 所以这句代码也就很简单了，将字符串指针s向后移动header的大小，也就得到了header的指针。（不过有个疑问是为什么还要重新获取headr的地址，最开始不就是指向了header吗？，难道memset是直接对sh进行操作的？测试过了，memset不会修改sh的地址，所以应该是为了再次确保sh一定指向header） 解释一下：SDS_HDR_VAR 的作用是将sh的类型修改为结构体指针，因为之前sh 一直都是空指针，(虽然指针的指向地址是headr，但是没有限定它类型)不然后面没法用sh-&gt;len, sh-&gt;alloc 来访问对应的结构体成员。 最开始创建的时候alloc 和len是一样大的，没有分配多余空间） memcpy(s, init, initlen); 函数将init的前initlen个字符拷贝给s。 memcpy源码为： 123456789101112/* Public domain. */#include &lt;stddef.h&gt;void *memcpy (void *dest, const void *src, size_t len)&#123; char *d = dest; const char *s = src; while (len--) *d++ = *s++; return dest;&#125; 整个过程中的三个指针sh,s,fp对应关系如下图 销毁销毁使用sdsfree来实现 源码为： 12345/* Free an sds string. No operation is performed if 's' is NULL. */void sdsfree(sds s) &#123; if (s == NULL) return; s_free((char*)s-sdsHdrSize(s[-1]));&#125; s[-1],就是指针s向后移动移位，也就是flag的位置。将s移动到sh的位置，释放sh指针也就释放了整个sds内存。 疑惑：sh指针在sdsnewlen函数中是个局部变量，在sdsnewlen函数中是自动释放的，这里并没有传递sh指针为什么也可以释放对应的空间？ 自己想了下：malloc 函数传递的参数是需要分配的内存大小(len)，返回的是指针也就是地址。free()函数只用将malloc函数返回的指针(地址)作为参数传入，就可以释放之前该地址分配到的内存空间。而地址只是首地址，总共的偏移量（大小），应该是由操作系统在内存分配的时候就记录了的。 博客中记录：申请的时候实际上占用的内存要比申请的大。因为超出的空间是用来记录对这块内存的管理信息。额外的空间用来记录管理信息——分配块的长度，指向下一个分配块的指针等等。果然malloc的时候用来一个struct来记录分配的信息。 1234struct mem_control_block &#123; int is_available; //一般来说应该是一个可用空间的首地址，但这里英文单词却显示出空间是否可用的一个标记 int size; //这是实际空间的大小 &#125;; http://www.cnblogs.com/hanyonglu/archive/2011/04/28/2031271.html free()就是根据这个结构体的信息来释放malloc()申请的空间 另外的疑惑：释放完空间后，s 指针不用把它指向null吗？ 暂时就只是创建和销毁的源码把，看了两天，阅读源码真的是酣畅淋漓，收获良多。学到了很多奇妙的C技巧，还对操作系统的知识有了更具象的理解。 其他阅读sdsfromlonglong部分的源码： sdsfromlonglong 函数用于将一个long long 类型的整形数字转换为字符数组。 12345678910/* Create an sds string from a long long value. It is much faster than: * * sdscatprintf(sdsempty(),"%lld\n", value); */sds sdsfromlonglong(long long value) &#123; char buf[SDS_LLSTR_SIZE]; // 给buf数组分配最小的空间，21的长度 int len = sdsll2str(buf,value); //将long long 转为字符数组存储在buf中，并返回字符串的长度 return sdsnewlen(buf,len);&#125; 可以看到主要的转换操作在sdsll2str这个函数中： 12345678910111213141516171819202122232425262728293031323334353637/* Helper for sdscatlonglong() doing the actual number -&gt; string * conversion. 's' must point to a string with room for at least * SDS_LLSTR_SIZE bytes. * * The function returns the length of the null-terminated string * representation stored at 's'. */#define SDS_LLSTR_SIZE 21int sdsll2str(char *s, long long value) &#123; char *p, aux; unsigned long long v; size_t l; /* Generate the string representation, this method produces * an reversed string. */ v = (value &lt; 0) ? -value : value; //判断是否为负数 p = s; do &#123; *p++ = '0'+(v%10); // 除以10取余数 v /= 10; //去除个位 &#125; while(v); if (value &lt; 0) *p++ = '-'; /* Compute length and add null term. */ l = p-s; // 计算出字符串的长度 不含终止符 *p = '\0'; // 首地址填终止符。 /* Reverse the string. */ p--; while(s &lt; p) &#123; aux = *s; *s = *p; *p = aux; s++; p--; &#125; return l;&#125; 1234do &#123; *p++ = '0'+(v%10); // 除以10取余数 v /= 10; //去除个位&#125; while(v); 假设v是352，变成字符串是将每一个对应的10进制上面的3,5,2这三个个位、十位、百位的数字给单独变成字符。 *p++ = &#39;0&#39;+(v%10); p 指针是字符数组buf的首地址，而将整型变成字符型的操作就是与字符’0’ 相加，这样就可以对应的数字变成字符类型。同时p相应的加1来指向下一个byte用来存储下一个被转换的char。 char类型存储的是对应字符的ascii值，ASCII表为：https://baike.baidu.com/item/ASCII/309296 ，所以字符的运算实际上是对应的ASCII的值的运算。v%10是除以10取余数，352%10 =2； 35%10=5，所以也就是取得v值的10进制上面的个位数。所以在while循环里面每次对v除以10并取余，就可以得到对应long long 型的字符串。但是因为每次得到的字符都是最后面的个位数，所以352，所输出的字符串数组为：‘2’， ‘3’， ‘5’ 是一个倒序的，因此还需要再反转一次。 123456789/* Reverse the string. */ p--;while(s &lt; p) &#123; aux = *s; *s = *p; *p = aux; s++; p--;&#125; 字符串反转，首尾各有一个指针，当首指针小于尾指针的时候，交换数字，并同时向中间移动 参考资料https://blog.csdn.net/yangbodong22011/article/details/78419966]]></content>
      <categories>
        <category>源码阅读</category>
      </categories>
      <tags>
        <tag>redis</tag>
        <tag>源码阅读</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis设计与实现读书笔记——第二章SDS]]></title>
    <url>%2F2019%2F03%2F20%2F2019-03-20-Redis%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B0%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[Redis设计与实现读书笔记——第二章为了做Redis相关实验，在网上粗略看了Redis设计与实现的电子版，感觉收获很多，但是因为是旧版，所以买了第二版，重读第二次。 第二章 简单动态字符串简介 字符串值的键值对在底层都是由SDS实现的。 sds的功能： 存储字符串值 用作缓冲区 AOF模块缓冲区 客户端状态的输入缓冲区 2.1 SDS的定义文件：sds.h/sdshdr 结构体 书中的为3.0版本，4.0版本有较大改动。 version: redis-4.02 参考：https://www.cnblogs.com/chenpingzhao/p/7292182.html https://www.codesheep.cn/2018/08/09/Redis%E5%AD%97%E7%AC%A6%E4%B8%B2%E7%B1%BB%E5%9E%8B%E5%86%85%E9%83%A8%E7%BC%96%E7%A0%81%E5%89%96%E6%9E%90/ 1234567891011121314151617181920212223242526272829303132typedef char *sds; //注意，sds其实不是一个结构体类型，而是被typedef的char*/* Note: sdshdr5 is never used, we just access the flags byte directly. * However is here to document the layout of type 5 SDS strings. */struct __attribute__ ((__packed__)) sdshdr5 &#123; unsigned char flags; /* 3 lsb of type, and 5 msb of string length */ char buf[];&#125;;struct __attribute__ ((__packed__)) sdshdr8 &#123; uint8_t len; /* used */ uint8_t alloc; /* excluding the header and null terminator */ unsigned char flags; /* 3 lsb of type, 5 unused bits */ char buf[];&#125;;struct __attribute__ ((__packed__)) sdshdr16 &#123; uint16_t len; /* used */ uint16_t alloc; /* excluding the header and null terminator */ unsigned char flags; /* 3 lsb of type, 5 unused bits */ char buf[];&#125;;struct __attribute__ ((__packed__)) sdshdr32 &#123; uint32_t len; /* used */ uint32_t alloc; /* excluding the header and null terminator */ unsigned char flags; /* 3 lsb of type, 5 unused bits */ char buf[];&#125;;struct __attribute__ ((__packed__)) sdshdr64 &#123; uint64_t len; /* used */ uint64_t alloc; /* excluding the header and null terminator */ unsigned char flags; /* 3 lsb of type, 5 unused bits */ char buf[];&#125;; 除了结构体字段对len和alloc的数据类型的不同(unit8, unit16， unit32, unit64)， 其字段含义相差无几。其中header记录len, alloc, flags 信息。不同的header的目的是节省内存。header与buf数组在内存地址上前后相邻。 12345+--------+-------------------------------+-----------+| Header | Binary safe C alike string... | Null term |+--------+-------------------------------+-----------+ | `-&gt; Pointer returned to the user. 1234len: 记录buf数组中已使用的字节数量 等于保存的字符串的长度 （不算结尾的\0 标识符）alloc: 字符串最大的容量。（除开header和最后的null终止符） flags: 总是会占用一个字节 8bit，加上unsigned是因为flags都是非负数 ，其中的最低3个bit用来表示header的类型还有 5个bit没有使用。buf: 字符数组，用于保存字符串。 柔性数组 buf的大小=alloc+1； header类型定义中，注意的地方： 在各个header的定义中使用了attribute ((packed))，是为了让编译器以紧凑模式来分配内存，取消字节对齐。 结构体的成员内存是’”连续”的，但是这个连续是以对齐的单位而言的。比如说A成员的内存是3个字节，假设对齐单位是4个字节，会给A成员多分配一个字节。A成员后面才又紧接B成员的内存。 如果没有这个属性，编译器可能会为struct的字段做优化对齐，在其中填充空字节。那样的话，就不能保证header和sds的数据部分紧紧前后相邻，也不能按照固定向低地址方向偏移1个字节的方式来获取flags字段了。 在各个header的定义中最后有一个char buf[]。我们注意到这是一个没有指明长度的字符数组，这是C语言中定义字符数组的一种特殊写法，称为柔性数组（flexible array member），只能定义在一个结构体的最后一个字段上。它在这里只是起到一个标记的作用，表示在flags字段后面就是一个字符数组，或者说，它指明了紧跟在flags字段后面的这个字符数组在结构体中的偏移位置。而程序在为header分配的内存的时候，它并不占用内存空间。如果计算sizeof(struct sdshdr16)的值，那么结果是5个字节，其中没有buf字段。 sdshdr5与其它几个header结构不同，它不包含alloc字段，而长度使用flags的高5位来存储。因此，它不能为字符串分配空余空间。如果字符串需要动态增长，那么它就必然要重新分配内存才行。所以说，这种类型的sds字符串更适合存储静态的短字符串（长度小于32）。 因为长度的范围是5个bit来存储的$$2^5-1 = 31$$ sds字符串的header，其实隐藏在真正的字符串数据的前面（低地址方向）。这样的一个定义，有如下几个好处 header和数据相邻，而不用分成两块内存空间来单独分配。这有利于减少内存碎片，提高存储效率（memory efficiency）。 虽然header有多个类型，但sds可以用统一的char *来表达。且它与传统的C语言字符串保持类型兼容。如果一个sds里面存储的是可打印字符串，那么我们可以直接把它传给C函数，比如使用strcmp比较字符串大小，或者使用printf进行打印。2.2 SDS与C字符串的区别 c语言使用N+1长度的字符数组来表示长度为N的字符串，因为需要增加一个\0 字符终止 2.2.1 常数复杂度获取字符串长度因为c语言要知道字符串的长度只能遍历数组，所以复杂度为O(N)。 而获取sds的字符串长度，只需要返回len的值就可以了复杂度为O(1)。这样对一个非常长的字符串键反复执行STRLEN命令，也不会对系统性能造成任何影响。 2.2.2 杜绝缓冲区溢出C字符串不记录自身长度会带来易造成缓冲区溢出的问题。 比如使用strcat函数拼接两个字符串，被拼接的字符串要是没有提前分配空间，就会造成缓冲区溢出。（溢出的字节会导致这个字符串内存紧邻的其他字符串的内容被修改） 而SDS的空间分配策略完全杜绝了发生缓冲区溢出的可能，SDS的API需要修改SDS时，会先检查空间alloc是否满足修改所需的要求。不满足的话会先将空间扩展至修改所需的大小，再执行修改。 2.2.3 减少修改字符串时带来的内存重分配次数C语言字符串用N+1个字节长的数组来保存N个字节的字符串，因为这个关联性所以每次每次增长或者缩短一个C字符串，都要对这个字符串进行一次内存重分配操作。 执行增长操作 比如append，需要首先通过内存重分配来扩展底层数组的空间大小，否则产生缓冲区溢出 执行所动操作比如截断操作trime，需要首先通过内存重分配来释放字符串不再使用的空间，否则造成内存泄漏。 内存重分配涉及复杂的算法，并且可能需要执行系统调用，所以通常是一个比较耗时的操作。这对Redis经常用于速度要求严苛，数据被频繁修改的场合来说，是不可接受的。 因此SDS通过未使用空间解除了字符串长度和底层数组长度之间的关联：buf的长度可以大于len的长度。 （4.0版本的源码还未找到对应的函数，所以可能和书上说的有变化了） 空间预分配 ——减少连续执行字符串增长操作所需的内存重分配次数。 用于优化字符串增长操作。 当需要对SDS的空间进行空间扩展时，不仅会对SDS分配修改所必需的空间，还会额外分配未使用空间。 当len &lt; 1Mb时 alloc = 2*len; 当len &gt;= 1 mb时 alloc= len +1Mb。 源码分析 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950/* Enlarge the free space at the end of the sds string so that the caller * is sure that after calling this function can overwrite up to addlen * bytes after the end of the string, plus one more byte for nul term. * * Note: this does not change the *length* of the sds string as returned * by sdslen(), but only the free buffer space we have. */sds sdsMakeRoomFor(sds s, size_t addlen) &#123; void *sh, *newsh; size_t avail = sdsavail(s); size_t len, newlen; char type, oldtype = s[-1] &amp; SDS_TYPE_MASK; int hdrlen; /* Return ASAP if there is enough space left. */ if (avail &gt;= addlen) return s; len = sdslen(s); sh = (char*)s-sdsHdrSize(oldtype); newlen = (len+addlen); // 预分配 if (newlen &lt; SDS_MAX_PREALLOC) newlen *= 2; else newlen += SDS_MAX_PREALLOC; type = sdsReqType(newlen); /* Don't use type 5: the user is appending to the string and type 5 is * not able to remember empty space, so sdsMakeRoomFor() must be called * at every appending operation. */ if (type == SDS_TYPE_5) type = SDS_TYPE_8; hdrlen = sdsHdrSize(type); if (oldtype==type) &#123; newsh = s_realloc(sh, hdrlen+newlen+1); if (newsh == NULL) return NULL; s = (char*)newsh+hdrlen; &#125; else &#123; /* Since the header size changes, need to move the string forward, * and can't use realloc */ newsh = s_malloc(hdrlen+newlen+1); if (newsh == NULL) return NULL; memcpy((char*)newsh+hdrlen, s, len+1); s_free(sh); s = (char*)newsh+hdrlen; s[-1] = type; sdssetlen(s, len); &#125; sdssetalloc(s, newlen); return s;&#125; 惰性空间释放 用于优化SDS的字符串缩短操作 缩短SDS保存的字符串时，并不立即使用内存重分配来回收缩短后多出来的字节，而是使用free属性，将这些字节的数量记录起来，并等待将来使用。 2.2.4 二进制安全C字符串中的字符必须符合某种编码（如ASCII），除了末尾字符串中间不能有\0 这个空字符，否则最先被程序读取的空字符将被认为是结尾，导致C字符串只能保存文本数据，而不能保存图片、音频、视频、压缩文件这样的二进制数据。 所谓二进制安全：以处理二进制的方式来处理SDS存放在buf数组里的数据，程序不会对其中的数据做任何限制、过滤、或者假设，数据在写入时是什么样的，被读取是就是什么样的。因为SDS使用len来判断字符串是否结束。 所以buf是字节数组，而不是字符数组。 2.2.5 兼容部分C字符串函数因为遵循C字符串以\0结尾的惯例，所以可以兼容&lt;string.h&gt;/strcasecmp ,&lt;stdio.h&gt;/printf 这些函数。但是是否是书上的使用结构体指针还是博客说的可以直接使用sds来调用？还需验证。 书：printf(&quot;%s&quot;, sds-&gt;buf) sds是指向结构体的指针。 博客：https://blog.csdn.net/yangbodong22011/article/details/78419966 :printf(%s, sds) 源码中是直接使用sds 2.2.6 总结 C字符串 SDS 获取字符串长度复杂度为O(N) 获取字符串长度复杂度为O(1) API不安全，可能造成缓冲区溢出 API安全，不会造成缓冲区溢出 修改字符串长度N次必然执行N次内存重分配 最多执行N次内存重分配 只能保存文本数据 二进制安全文本与二进制数据皆可 可使用&lt;string.h&gt;库中所有函数 部分使用&lt;string.h&gt;库中函数 2.3 SDSAPI 函数 作用 sdslen(const sds s) 获取sds字符串长度 O（1） sdssetlen(sds s, size_t newlen) 设置sds字符串长度 sdsinclen(sds s, size_t inc) 增加sds字符串长度 sdsalloc(const sds s) 获取sds字符串容量 sdssetalloc(sds s, size_t newlen) 设置sds字符串容量。 sdsavail(const sds s) 获取sds字符串空余空间（即alloc - len） sdsHdrSize(char type) 根据header类型得到header大小 sdsReqType(size_t string_size) 根据字符串数据长度计算所需要的header类型。 sdsReqType函数源码分析12345678910111213static inline char sdsReqType(size_t string_size) &#123; if (string_size &lt; 1&lt;&lt;5) // string_size &lt; 2^5 return SDS_TYPE_5; if (string_size &lt; 1&lt;&lt;8) //string_size &lt; 2^8 return SDS_TYPE_8; if (string_size &lt; 1&lt;&lt;16) //string_size &lt; 2^16 return SDS_TYPE_16;#if (LONG_MAX == LLONG_MAX) if (string_size &lt; 1ll&lt;&lt;32) //string_size &lt; 2^32 return SDS_TYPE_32;#endif return SDS_TYPE_64; &#125; 采用左移来计算对应多少位的范围，而不是用2^5 这样的乘法。直接移位比使用幂来计算快很多。 1&lt;&lt;5 计算出来就是2^5 次方。1是int型，4byte32位。最低8bit位的二进制为：00000001 左移5位后变成了：00100000 对应的十进制既是32。 计算n个bit位的最大值：(1&lt;&lt;n) -1 但是需要注意位数不够的情况。因为1是int型，只有32个bit。所以在左移32个bit时，需要使用long long int型。用1ll来表示，此时1ll为64个bit。 还得考虑机器是否为64位机器，在32位机器上LONG_MAX = 2147483647L，64位机器上LONG_MAX = 9223372036854775807L 。不论32位机器还是64位机器上 LLONG_MAX 都是9223372036854775807L 。所以当LONG_MAX == LLONG_MAX 说明字长为64bit。加上条件编译，说明在32位机器上不使用sdshdr32而直接跳到了sdshdr64，仅仅在64位机器上使用sdshdr32。原因是什么？还没想通 问题 为什么Redis需要自己实现字符串功能，而不直接使用c语言的传统字符串？ 见第二节。 执行SET 与GET命令的过程。 char buf[] 为什么没有指定大小？一个数组占用的内存大小 在各个header的定义中最后有一个char buf[]。我们注意到这是一个没有指明长度的字符数组，这是C语言中定义字符数组的一种特殊写法，称为柔性数组（flexible array member），只能定义在一个结构体的最后一个字段上。它在这里只是起到一个标记的作用，表示在flags字段后面就是一个字符数组，或者说，它指明了紧跟在flags字段后面的这个字符数组在结构体中的偏移位置。而程序在为header分配的内存的时候，它并不占用内存空间。如果计算sizeof(struct sdshdr16)的值，那么结果是5个字节，其中没有buf字段。 数组内存大小为分配的的长度*数组类型的内存大小 为什么redis 在32位机器上不使用sdshdr32？]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>redis</tag>
        <tag>源码阅读</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ping 无法连接外网]]></title>
    <url>%2F2019%2F03%2F15%2Fping%20%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[ping 无法连接外网 问题ping外网ping不通 1234yky@hw076:~/tmux&gt; ping www.baidu.comping: unknown host www.baidu.comyky@hw076:~/tmux&gt; ping 8.8.8.8connect: Network is unreachable ping内网可以ping通 12345678910hw076:~ # ping 172.18.11.114PING 172.18.11.114 (172.18.11.114) 56(84) bytes of data.64 bytes from 172.18.11.114: icmp_seq=1 ttl=64 time=0.193 ms64 bytes from 172.18.11.114: icmp_seq=2 ttl=64 time=0.216 ms64 bytes from 172.18.11.114: icmp_seq=3 ttl=64 time=0.207 ms64 bytes from 172.18.11.114: icmp_seq=4 ttl=64 time=0.200 ms^C--- 172.18.11.114 ping statistics ---4 packets transmitted, 4 received, 0% packet loss, time 2999msrtt min/avg/max/mdev = 0.193/0.204/0.216/0.008 ms ifconfig信息为： 12345678910111213141516171819hw076:~ # ifconfig eth0 Link encap:Ethernet HWaddr 90:E2:BA:15:C9:C4 inet addr:172.18.11.76 Bcast:192.168.1.255 Mask:255.255.0.0 inet6 addr: fe80::92e2:baff:fe15:c9c4/64 Scope:Link UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 RX packets:9725797 errors:0 dropped:506 overruns:0 frame:0 TX packets:21023 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1000 RX bytes:598731249 (570.9 Mb) TX bytes:2767270 (2.6 Mb) Memory:fb480000-fb500000 lo Link encap:Local Loopback inet addr:127.0.0.1 Mask:255.0.0.0 inet6 addr: ::1/128 Scope:Host UP LOOPBACK RUNNING MTU:65536 Metric:1 RX packets:276 errors:0 dropped:0 overruns:0 frame:0 TX packets:276 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:0 RX bytes:25088 (24.5 Kb) TX bytes:25088 (24.5 Kb) route显示路由信息如下： 1234567hw076:/etc/netconfig.d # routeKernel IP routing tableDestination Gateway Genmask Flags Metric Ref Use Ifacedefault * 0.0.0.0 UG 0 0 0 eth0loopback * 255.0.0.0 U 0 0 0 lolink-local * 255.255.0.0 U 0 0 0 eth0172.18.0.0 * 255.255.0.0 U 0 0 0 eth0 原因是route没有配置网关，gateway是空着的。 解决方法通过查看其他可以正常访问的节点的路由信息，得知网关节点为：172.18.0.254。因此增加默认网关节点配置。 执行命令： 1route add default gw 172.18.0.254 再次查看路由信息： 1234567hw076:~ # routeKernel IP routing tableDestination Gateway Genmask Flags Metric Ref Use Ifacedefault 172.18.0.254 0.0.0.0 UG 0 0 0 eth0loopback * 255.0.0.0 U 0 0 0 lolink-local * 255.255.0.0 U 0 0 0 eth0172.18.0.0 * 255.255.0.0 U 0 0 0 eth0 再次ping8.8.8.8显示正常，问题解决。]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>运维</tag>
        <tag>网络问题</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[shell 脚本遍历redis数据库]]></title>
    <url>%2F2019%2F03%2F14%2F%E4%BD%BF%E7%94%A8shell%E8%84%9A%E6%9C%AC%E9%81%8D%E5%8E%86redis%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B8%AD%E7%9A%84%E6%89%80%E6%9C%89kv%E5%AF%B9%2F</url>
    <content type="text"><![CDATA[使用shell脚本遍历redis数据库中的所有kv对记录下如何使用shell通过redis-cli 命令来操作redis数据库，因为直接在命令行中输入 redis-cli command 的话command必须是单个单词，不能像是KEYS * 这种. 123456789101112#!/bin/bashfilename=&apos;redis&apos;`date +%Y-%m-%d_%H:%M`work_path=$(dirname &quot;$0&quot;) echo &quot;实例化redis数据文件为:$work_path/$filename&quot;echo &quot;keys *&quot; | redis-cli &gt; key_db.txtecho &quot;将所有key保存到:$work_path/key_db.txt&quot;for line in `cat key_db.txt`do echo &quot;key:$line &quot; &gt;&gt;$work_path/$filename.txt echo &quot;key-value:&quot; &gt;&gt;$work_path/$filename.txt echo &quot;hgetall $line&quot; | redis-cli &gt;&gt;$work_path/$filename.txtdone 使用echo 来把命令输出到管道然后再传递给redis-cli。在循环里面也是使用echo来把字符串输入到文件中。]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>redis</tag>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用YCSB 评测redis性能]]></title>
    <url>%2F2019%2F03%2F12%2F%E4%BD%BF%E7%94%A8YCSB%20%E8%AF%84%E6%B5%8Bredis%E6%80%A7%E8%83%BD%2F</url>
    <content type="text"><![CDATA[使用YCSB 评测redis性能YCSB是雅虎推出的可以评测许多主流数据库性能的基准测试，其中包括Redis。 安装YCSB 安装java和maven 机子已经有了java，所以只用安装maven Ubuntu安装命令为： sudo apt-get install maven 安装YCSB 123git clone http://github.com/brianfrankcooper/YCSB.gitcd YCSBmvn -pl com.yahoo.ycsb:redis-binding -am clean package 必须是gitclone的源码包才能执行mvn 命令。wget或者curl下来包是已经编译好了的无需执行mvn命令。 mvn -pl com.yahoo.ycsb:redis-binding -am clean package 报错： 123456789[INFO] Scanning for projects...[ERROR] [ERROR] Could not find the selected project in the reactor: com.yahoo.ycsb:redis-binding @ [ERROR] Could not find the selected project in the reactor: com.yahoo.ycsb:redis-binding -&gt; [Help 1][ERROR] [ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.[ERROR] Re-run Maven using the -X switch to enable full debug logging.[ERROR] [ERROR] For more information about the errors and possible solutions, please read the following articles:[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MavenExecutionException 原因：此命令是在gitclone后未编译的时候使用的。而我之前是下载的编译好的tar.gz包，解压后是已经编译好了的。所以再次执行编译的命令时会报错。 使用YCSB将redis-server启动后开始使用YCSB 设置数据库需要先创建usertable的表，因为YCSB客户端默认是对usertable 进行操作。Redis将数据存储在内存中，不需要相关操作。 选择合适的DB interfaceYCSB的操作是通过DB interface来实现的。最基本的DB interface是com.yahoo.ycsb.BasicDB，会将输出输出到System.out里。可以通过继承DB interface来自定义DB interface，也可以使用原有的DB interface。Redis不需要此步操作。 选择合适的负载YCSB提供了6种负载，负载在worloads目录下。详情见https://github.com/brianfrankcooper/YCSB/wiki/Core-Workloads Workload A: Update heavy workload 读写比例为： 50/50 混合负载 Workload A: Update heavy workload 读写比例为：95/5 读为主的负载 Workload C: Read only 100% 的读 只读负载 Workload D: Read latest workload 读取最近的数据负载 Workload E: Short ranges 小范围的查询负载 Workload F: Read-modify-write 读修改写负载 自定义负载：参考https://github.com/brianfrankcooper/YCSB/wiki/Implementing-New-Workloads 可以通过修改参数文件或者新建java类来实现 需要注意的是YCSB的读写负载是针对哈希类型的数据而不是简单的字符串 指定需要的运行参数主要是指定redis的ip ，端口，密码等。 命令如下： 1./bin/ycsb load redis -s -P workloads/workloada -p &quot;redis.host=127.0.0.1&quot; -p &quot;redis.port=6379&quot; &gt; outputLoad.txt -s : status.十秒打印一次状态 加载负载命令如下： 1./bin/ycsb load redis -s -P workloads/workloada &gt; outputLoad.txt 运行负载命令如下： 1./bin/ycsb run redis -s -P workloads/workloada &gt; outputRun.txt 可以使用basic数据库来打印YCSB向数据库中写入的具体数据 12bin/ycsb.sh load basic -P workloads/workloadabin/ycsb.sh run basic -P workloads/workloada 参考https://datawine.github.io/2018/12/11/YCSB%E9%A1%B9%E7%9B%AE%E5%AD%A6%E4%B9%A0/ https://github.com/brianfrankcooper/YCSB/tree/master/redis]]></content>
      <tags>
        <tag>redis</tag>
        <tag>benchmark</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[apt-get install失败]]></title>
    <url>%2F2019%2F03%2F10%2Fapt-get%20install%20%E5%A4%B1%E8%B4%A5%2F</url>
    <content type="text"><![CDATA[apt-get install失败 第一阶段 使用perf 报错 内核无法找到perf 12345678910root@hw103:/home/yky/redis-5.0.3# perf WARNING: perf not found for kernel 4.15.0-45 You may need to install the following packages for this specific kernel: linux-tools-4.15.0-45-generic linux-cloud-tools-4.15.0-45-generic You may also want to install one of the following packages to keep up to date: linux-tools-generic linux-cloud-tools-generic 安装此内核的通用工具时错误 1234567891011root@hw103:/home/yky/redis-5.0.3# apt-get install linux-tools-4.15.0-45-genericReading package lists... DoneBuilding dependency tree Reading state information... DoneYou might want to run &apos;apt-get -f install&apos; to correct these:The following packages have unmet dependencies: console-setup : Depends: keyboard-configuration (= 1.178ubuntu2.7) but 1.108ubuntu15.3 is to be installed console-setup-linux : Depends: keyboard-configuration (= 1.178ubuntu2.7) but 1.108ubuntu15.3 is to be installed Breaks: keyboard-configuration (&lt; 1.138) but 1.108ubuntu15.3 is to be installed linux-tools-4.15.0-45-generic : Depends: linux-tools-4.15.0-45 but it is not going to be installedE: Unmet dependencies. Try &apos;apt-get -f install&apos; with no packages (or specify a solution). 使用apt-get -f install 时报错 123456789update-rc.d: error: insserv rejected the script headerdpkg: error processing archive /var/cache/apt/archives/keyboard-configuration_1.178ubuntu2.7_all.deb (--unpack): subprocess new pre-installation script returned error exit status 1dpkg-query: warning: files list file for package &apos;keyboard-configuration&apos; missing; assuming package has no files currently installeddpkg-query: warning: files list file for package &apos;keyboard-configuration&apos; missing; assuming package has no files currently installeddpkg-query: warning: files list file for package &apos;keyboard-configuration&apos; missing; assuming package has no files currently installedErrors were encountered while processing: /var/cache/apt/archives/keyboard-configuration_1.178ubuntu2.7_all.debE: Sub-process /usr/bin/dpkg returned an error code (1) 问题综述： apt-get install lib时报错 Unmet dependencies apt-get install -f 时报错Sub-process /usr/bin/dpkg returned an error code (1) 第一阶段解决办法 在/var/lib/dpkg/目录下有个info文件 ，然后文件中没有keyboard-configuration的相关文件但是有info的备份info_backup ，这里面有相关的文件，于是将keyboard-configuration的所有相关文件都拷贝到了/var/lib/dpkg/info 中。 在info_backup目录下执行如下命令拷贝 cp keyboard-configuration.* ../info 随后再次执行安装内核通用工具 报错为第二阶段 第二阶段 安装此内核的通用工具时时报错： 123456789101112131415161718192021222324252627282930313233insserv: Starting redis depends on plymouth and therefore on system facility `$all&apos; which can not be true!insserv: exiting now without changing boot order!update-rc.d: error: insserv rejected the script headerdpkg: error processing package avahi-daemon (--configure): subprocess installed post-installation script returned error exit status 1No apport report written because MaxReports is reached already No apport report written because MaxReports is reached already dpkg: dependency problems prevent configuration of avahi-utils: avahi-utils depends on avahi-daemon; however: Package avahi-daemon is not configured yet.dpkg: error processing package avahi-utils (--configure): dependency problems - leaving unconfiguredSetting up unattended-upgrades (1.1ubuntu1.18.04.9) ...dpkg: error processing package unattended-upgrades (--configure): subprocess installed post-installation script returned error exit status 10No apport report written because MaxReports is reached already Setting up linux-tools-4.15.0-45 (4.15.0-45.48) ...Setting up linux-tools-4.15.0-45-generic (4.15.0-45.48) ...Processing triggers for initramfs-tools (0.122ubuntu8.14) ...Errors were encountered while processing: udev snapd ubuntu-core-launcher kmod ubuntu-drivers-common whoopsie openssh-server ssh avahi-daemon avahi-utils unattended-upgradesE: Sub-process /usr/bin/dpkg returned an error code (1) 解决办法：/var/lib/dpkg/info 目录下将上述出现问题的模块的postinst文件重命名。 在/var/lib/dpkg/info 下写了个脚本 solution.sh 12345#!/bin/bashfor pack in $(cat module.txt)do mv &quot;$pack&quot;.postinst &quot;$pack&quot;.postinst.bakdone 其中module.txt的内容为 1234567891011udevsnapdubuntu-core-launcherkmodubuntu-drivers-commonwhoopsieopenssh-serversshavahi-daemonavahi-utilsunattended-upgrades 执行脚本后 使用sudo apt-get upgrade 进行更新 参考： https://www.codelast.com/%E5%8E%9F%E5%88%9B-%E8%A7%A3%E5%86%B3ubuntu-%E6%97%A0%E6%B3%95%E7%94%A8-apt-get-install-%E5%AE%89%E8%A3%85%E4%BB%BB%E4%BD%95%E8%BD%AF%E4%BB%B6dpkg-error-processing-package-xxx%E7%9A%84%E9%97%AE/ https://askubuntu.com/questions/949760/dpkg-warning-files-list-file-for-package-missing]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>运维</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Make学习]]></title>
    <url>%2F2018%2F10%2F09%2Fmake%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[make学习开始阅读redis源码，都说redis很简单，源码不多。但是源码包下载下来后却发现不知道从何处入手，有那么多文件和源码。后面查找资料才发现阅读源码的第一步就是阅读Makefile，项目如何构建和源码间的关联都写在了Makefile文件中。之前没有接触过Makefile，记录下Make的学习。 makefile的格式 概述 makefile 文件由一系列rules组成 rules的格式为： 12&lt;target&gt; : &lt;prerequisites&gt; [tab] &lt;commands&gt; ​ “目标”是必需的，不可省略；”前置条件”和”命令”都是可选的，但是两者之中必须至少存在一个。 ​ 每条规则就明确两件事：构建目标的前置条件是什么，以及如何构建。 target 一个目标（target）就构成一条规则。目标通常是文件名，指明Make命令所要构建的对象，比如上文的 a.txt 目标可以是一个文件名，也可以是多个文件名，之间用空格分隔。（make的时候指定文件名从而对该文件进行构建build） 除了文件名，目标还可以是某个操作的名字，这称为”伪目标”（phony target）。伪目标不生成文件，只执行命令。 比如： 12clean: rm *.o 此时执行make clean 命令则会进行rm *.o 的操作。 但是当存在clean这个文件时，那么这个命令不会执行。因为Make发现clean文件已经存在，就认为没有必要重新构建了，就不会执行指定的rm命令。 为了避免这种情况，可以明确声明clean是”伪目标”，写法如下。 123.PHONY: cleanclean: rm *.o temp 如果Make命令运行时没有指定目标，默认会执行Makefile文件的第一个目标。 prerequisites 前置条件通常是一组文件名，之间用空格分隔。它指定了”目标”是否重新构建的判断标准：只要有一个前置文件不存在，或者有过更新（前置文件的last-modification时间戳比目标的时间戳新），”目标”就需要重新构建。 没有前置条件，就意味着它跟其他文件都无关，只要这个target文件还不存在 就需要执行命令构建 如果需要生成多个文件，往往采用下面的写法。 source: file1 file2 file3 无需加上命令，当三个文件不存在时，执行make source就会生成这三个文件。 commands 命令（commands）表示如何更新目标文件，由一行或多行的Shell命令组成。它是构建”目标”的具体指令，它的运行结果通常就是生成目标文件。 每行命令之前必须有一个tab键 需要注意的是，每行命令在一个单独的shell中执行。这些Shell之间没有继承关系。 123var-lost: export foo=bar echo &quot;foo=[$$foo]&quot; 上面代码执行后（make var-lost），取不到foo的值。因为两行命令在两个不同的进程执行。 解决办法： 命令写在同1行 换行符前加反斜杠转义 123var-kept: export foo=bar; \ echo &quot;foo=[$$foo]&quot; 加上.ONESHELL:命令 1234.ONESHELL:var-kept: export foo=bar; echo &quot;foo=[$$foo]&quot; makefile的语法 注释 井号（#）在Makefile中表示注释。 回声（echoing） 正常情况下，make会打印每条命令，然后再执行，这就叫做回声（echoing）。 在命令的前面加上@，就可以关闭回声。 由于在构建过程中，需要了解当前在执行哪条命令，所以通常只在注释和纯显示的echo命令前面加上@。 通配符 由于在构建过程中，需要了解当前在执行哪条命令，所以通常只在注释和纯显示的echo命令前面加上@。 模式匹配 Make命令允许对文件名，进行类似正则运算的匹配，主要用到的匹配符是%。比如，假定当前目录下有 f1.c 和 f2.c 两个源码文件，需要将它们编译为对应的对象文件。 1%.o: %.c 等同于 12f1.o: f1.cf2.o: f2.c 使用匹配符%，可以将大量同类型的文件，只用一条规则就完成构建。 变量和赋值符 Makefile 允许使用等号自定义变量。 123txt = Hello Worldtest: @echo $(txt) 上面代码中，变量 txt 等于 Hello World。调用时，变量需要放在 $( ) 之中 调用Shell变量，需要在美元符号前，再加一个美元符号，这是因为Make命令会对美元符号转义。 内置变量 Make命令提供一系列内置变量，比如，$(CC) 指向当前使用的编译器，$(MAKE) 指向当前使用的Make工具。这主要是为了跨平台的兼容性 gmake、cmake、dmake等等。 自动变量 $@指代当前目标，就是Make命令当前构建的那个目标 target $&lt;指代第一个前置条件。比如，规则为 t: p1 p2，那么$&lt; 就指代p1 $？指代比目标更新的所有前置条件，之间以空格分隔。比如，规则为 t: p1 p2，其中 p2 的时间戳比 t 新，$?就指代p2。 $^指代所有前置条件，之间以空格分隔。比如，规则为 t: p1 p2，那么 $^ 就指代 p1 p2 。 $指代匹配符 % 匹配的部分， 比如% 匹配 f1.txt 中的f1 ，$ 就表示 f1。 $(@D) 和 $(@F)$(@D) 和 $(@F) 分别指向 $@ 的目录名和文件名。比如，$@是 src/input.c，那么$(@D) 的值为 src ，$(@F) 的值为 input.c。 $(&lt;D) 和 $(&lt;F) $(&lt;D) 和 $(&lt;F) 分别指向 $&lt; 的目录名和文件名。 其他 .DEFAULT：表示找不到匹配规则时，就执行该recipe。 123default:all.DEFAULT: commands 这里当执行make default 时会转到make all 因为default：all 这个target没有隐式规则。所以最后会执行commands。 忽略命令的出错，可以在Makefile的命令行前加一个减号”-“(在Tab键之后)，标记为不管命令出不出错都认为是成功的。如： 12clean: -(rm -f *.o ) include filename 将filename中的内容导入，如果找不到会停止make， -include filename 则不会停止make。 几种等号= 是最基本的赋值:= 是覆盖之前的值?= 是如果没有被赋值过就赋予等号后面的值+= 是添加等号后面的值 =与:= 的区别 =：make会将整个makefile展开后，再决定变量的值。也就是说，变量的值将会是整个makefile中最后被指定的值。例子为： 123x = fooy = $(x) barx = xyz y的值将会是 xyz bar ，而不是 foo bar 。因为展开后最终变成的是xyz :=表示变量的值决定于它在makefile中的位置，而不是整个makefile展开后的最终值。 123x := fooy := $(x) barx := xyz y的值将会是 foo bar ，而不是 xyz bar 了。 参考资料： http://www.ruanyifeng.com/blog/2015/02/make.html https://gist.github.com/isaacs/62a2d1825d04437c6f08 makefile文件教程 https://www.gnu.org/software/make/manual/make.html GNUmake手册 https://blog.csdn.net/shouso888/article/details/7226030 等号解释]]></content>
      <categories>
        <category>编程语言</category>
      </categories>
      <tags>
        <tag>make</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux命令学习之wc]]></title>
    <url>%2F2018%2F07%2F09%2FLinux%20%E5%91%BD%E4%BB%A4%20%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[Linux 命令学习wc命令wc命令 作用：Word Count 功能为统计指定文件中的字节数、字数、行数，并将统计结果显示输出。 格式： wc [option] filepath 参数 -c 统计字节数 -l 统计行数 -m 统计字符数 标志不能与 -c 标志一起使用。 -w 统计字（单词word）数。一个字被定义为由空白、跳格或换行字符分隔的字符串 -L 打印最长行的长度。 -help 显示帮助信息 --version 显示版本信息 参考网址：http://www.cnblogs.com/peida/archive/2012/12/18/2822758.html]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>command</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[make 2>&1 | tee log.txt 命令解析]]></title>
    <url>%2F2018%2F06%2F23%2Ftee%E5%91%BD%E4%BB%A4%E8%A7%A3%E6%9E%90%2F</url>
    <content type="text"><![CDATA[make 2&gt;&amp;1 | tee log.txt 命令解析在安装mpich 的时候遇到了很多这个命令，此处学习下这个命令：2&gt;&amp;1 | tee log.txt 这个命令共有三个部分： 2&gt;&amp;1 | tee log.txt 2&gt;&amp;1shell中：最常使用的 FD (file descriptor) 大概有三个 0表示标准输入Standard Input (STDIN) 1表示标准输出Standard Output (STDOUT) 2表示标准错误输出 Standard Error Output (STDERR) ‘&gt;’ 默认为标准输出重定向 （类似于c++ 中的 &gt;&gt;？） 在标准情况下, 这些FD分别跟如下设备关联 stdin(0): keyboard 键盘输入,并返回在前端 stdout(1): monitor 正确返回值 输出到前端 stderr(2): monitor 错误返回值 输出到前端 1&gt;&amp;2 正确返回值传递给2输出通道 &amp;2表示2输出通道 如果此处错写成 1&gt;2, 就表示把1输出重定向到文件2中 2&gt;&amp;1 错误返回值传递给1输出通道, 同样&amp;1表示1输出通道. |管道管道的作用是提供一个通道，将上一个程序的标准输出重定向到下一个程序作为下一个程序的标准输入。 tee log.txttee从标准输入中读取，并将读入的内容写到标准输出以及文件中。 此处将数据读入并写入到log.txt中 总结这个命令将标准错误输出重定向到标准输出，然后再将标准输出重定向到log.txt文件中 常用于make 后面将log信息保存下来。]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>command</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[BigdataBench deploy]]></title>
    <url>%2F2018%2F06%2F23%2FBigdataBench-deploy%2F</url>
    <content type="text"><![CDATA[Bigdatabench 4.0 MPI版本 安装 官网上面的指南BigDataBench User Manual有一些错误。 本机环境： ​ Centos 6.9 ​ gcc (GCC) 4.8.2 20140120 (Red Hat 4.8.2-15) ​ g++ (GCC) 4.8.2 20140120 (Red Hat 4.8.2-15) mpi的安装这部分网上资料很多，而Manual中有一点错误 需要保证c 编译器 如gcc c++ 编译器 如：g++ 基础安装 从官网下载安装包解压 wget http://www.mpich.org/static/downloads/3.2.1/mpich-3.2.1.tar.gz 从官网下载安装包 tar -zxvf mpich-3.2.1.tar.gz 解压 cd mpich-3.2.1 配置安装目录 本机安装在mpich-install目录下 ./configure –prefix=/home/mpich-install 2&gt;&amp;1 | tee c.txt 手册中&amp;被错写为$了 2&gt;&amp;1 | tee c.txt 表示将输出的标准出错信息重定向到c.txt中。 build make 2&gt;&amp;1 | tee m.txt 安装 make install 2&gt;&amp;1 | tee mi.txt 将安装目录添加到PATH 环境变量中 vim ~/.bashrc export PATH=$PATH:/home/mpich-install/bin 在最后一行添加 source ~/.bashrc 重启生效 检查 检查路径 which mpicc which mpic++ 验证 在mpich的安装包目录下有提供例子程序运行 cd mpich-3.2.1/examples mpicc cpi.c -o cpi 编译cpi.c程序求pi值 mpirun -n 4 ./cpi 使用4个进程 注意./否则报错找不到文件 如果是集群环境在每个节点将mpich安装在相同的路径然后编辑一个machine_file （里面是各个节点的host）然后mpirun -f machine_file -n 3 ./cpi 在集群上并行运行 boost 安装boost当前最新版本是：1.67 但是BigdataBench用的是1.43版本推荐安装这个旧版本 wget https://sourceforge.net/projects/boost/files/boost/1.43.0/boost_1_43_0.tar.gz/download 若下载下来的文件名为：downloads 则使用mv命令重命名在当前文件目录下: mv downloads boost_1_43_0.tar.gz 解压tar -zxvf boost_1_43_0.tar.gz 之后cd boost_1_43_0 sh bootstrap.sh 执行这个命令运行脚本后会多出很多配置文件 使用mpi,这一步骤很重要否则后续cmake时会提示找不到：boost_mpi 对低版本的boost which mpic++ 找mpich的目录 vim tools/build/v2/user-config.jam 在最后添加： using mpi:后面是mpich的目录 #MPI config using mpi : /usr/lib64/mpich/bin/mpic++ ; 对高版本的boost直接在boost_1_67_0目录下修改project-config.jam即可 ./bjam 进行编译 ./bjam install 这一步是必需的但在手册中没有表明。 BigdataBench的配置进入BigDataBench的安装根目录： vim conf.properties 添加$JAVA_HOME， $MPI_HOME ，$BigdataBench_HOMEMPI的路径 sh prepar.sh 至此安装理论上已经成功。但仍然遇到了其他问题 Perminsion denied问题最开始的安装包是从windows下面考过去的结果生成cc的数据后无法运行执行脚本 原因是此时的run_connectedComponents已经不是可执行文件了（不是绿色的）需要chmod a+x run_connectedComponents来将文件的权限修改为可执行文件权限（修改后变为绿色） 后面wget下载后解压配置之后直接就是可执行文件！ ldd 程序 动态链接库缺失[root@hw073 ConnectedComponent]# ldd run_connectedComponentslinux-vdso.so.1 =&gt; (0x00007ffdfc8d4000)librt.so.1 =&gt; /lib64/librt.so.1 (0x0000003156e00000)libpthread.so.0 =&gt; /lib64/libpthread.so.0 (0x0000003156a00000) libboost_serialization-mt.so.1.43.0 =&gt; not foundlibboost_filesystem-mt.so.1.43.0 =&gt; not foundlibboost_system-mt.so.1.43.0 =&gt; not foundlibstdc++.so.6 =&gt; /usr/lib64/libstdc++.so.6 (0x0000003162200000)libm.so.6 =&gt; /lib64/libm.so.6 (0x0000003157200000)libgcc_s.so.1 =&gt; /lib64/libgcc_s.so.1 (0x0000003161a00000)libc.so.6 =&gt; /lib64/libc.so.6 (0x0000003156600000)/lib64/ld-linux-x86-64.so.2 (0x0000003155e00000) 最开始以为是没有指定LD_LIBRARY_PATH ，因为明明有这个文件的，后面使用find / -name 命令发现还是找不到，仔细一看ldd 的信息，发现上述文件都多了个-mt 解决办法： 在boost安装时的库。本机：/usr/local/lib 有着及其相似的3个文件libboost_filesystem.so.1.43.0 、libboost_filesystem.so.1.43.0 ，libboost_system.so.1.43.0 均少了个-mt，因此将上述三个文件均拷贝一份命名为上述缺少的动态库文件。 cd /usr/local/lib #切换到对应的目录下 cp libboost_system.so.1.43.0 libboost_system-mt.so.1.43.0 #拷贝为对应的文件名]]></content>
      <categories>
        <category>deploy</category>
      </categories>
      <tags>
        <tag>bigdatabench</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[图计算常用算法]]></title>
    <url>%2F2018%2F04%2F24%2F%E5%9B%BE%E8%AE%A1%E7%AE%97%E5%B8%B8%E7%94%A8%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[图算法的典型操作关于一些常见图算法的调研与学习。 常用图算法PageRank 背景 既考虑入链数量，又考虑了网页质量因素，二者相结合 数量与权重的结合 算法与主题无关，因为PR值是根据图计算出来的 算法原理 基本思想 A有链接指向B，表明A认为B比A重要。A将自身权重分配一部分给B。 $W(B)=W(A)/N$ W(A) 是A的PR值，W(B)是A 分配的权重，N是A的出链数 PageRank公式修正 存在出链为0的孤立网页，增加阻力系数q ，一般取q=0.85，其意义是用户有1-q的概率不点击此页面上面的所有链接。同时还有随机直接跳转的概率，如直接输入网址，点击书签等。完整公式如下： Connected component 定义 连通分支：图中，某个子图的任意两点有边连接，而子图之间无边连接 问题：cc是寻找连通分支的算法？？ 通过BFS、DFS算法的便利就可以找到连通分支，每个白色节点开始的就是一个连通分支。 常见算法 DFS 原理：访问某个顶点后只有当某个节点是叶结点后才会访问其余相邻节点。 步骤： 选择一个结点作为起始结点，标记为灰色 从该节点的邻居结点中选择一个结点，标记为灰色，继续这个操作 当选中的结点时叶子结点时，将其涂黑并返回到上一个父节点。 重复2,3直到所有结点都被访问。 BFS （DFS，BFS不是图的遍历算法吗）。 原理：在进一步遍历中顶点之前，先访问当前结点的所有邻接结点。 步骤： 选择一个顶点作为起始节点，放入队列，标记为灰色，其余标记为白色 寻找队列首部结点的所有邻居节点，将其放入队列中并标记为灰色，将队列首部结点出队，并标记为黑色 重复2步骤，直到队列中的节点全部为空。 SSSP (single-source shortest paths) 单独的起点与目标点之间最短路径的计算。起点固定，寻找与其他所有结点之间的最短路径。包括单源单汇，单源多汇 常见算法 Dijkstra 步骤 将所有顶点分成两个集合A、B，其中集合A表示已经求得从V0出发的最短路径的顶点集合，集合B为为待求解的顶点集合。初始时有A={V0} 将集合A与集合B相连的边（A中的所有结点与B中所有的结点形成的边）按照从V0出发的最短权重和递增次序排序，取最短的边，将该条边在集合B中所对应的顶点加入到集合A中 重复第二步，直至B为空集。 总结： 最短中的最短：每次迭代时比较的是当前状态下以V0为起点，A中顶点为中间点的到各顶点之间的最短路径权重，最后再选择在当前所有最短路径中路径最短的一个顶点加入A。也就是说每次加入A集合的点是最短路径中的最短。 给定目标点，在每次迭代时，并不知道能否到达最后的目标点，所以把到所有结点的最短距离都算出来了。 Betweenness Centrality（中介中心性） 定义 ：中心性用来衡量节结点的重要性。Betweenness Centrality ：考虑的是该节点出现在其他两节点之间的最短路径上的比率。 思想：如果一个成员位于其他成员的多条最短路上，那么该成员就是核心成员，就具有较大的中介中心性。 步骤 其中表示的是节点s和t之间的最短路径的数量，而是最短路径中经过节点v的数量。 计算各个点对之间最短路径的长度和条数，用于计算pair-dependencies: δst(v) =σst(v)/σst 对于每个节点，累积属于自己的pair-dependencies LBP算法(Local Binary Pattern, 局部二值模式) 定义：LBP是一种用来描述图像局部纹理特征的算子。 原始的LBP算子定义为在3*3的窗口内，以窗口中心像素为阈值，将相邻的8个像素的灰度值与其进行比较，若周围像素值大于中心像素值，则该像素点的位置被标记为1，否则为0 作用是进行特征提取，而且，提取的特征是图像的纹理特征，并且，是局部的纹理特征. 改进版本 原型LBP算子 LBP等价模式 最小生成树 定义：无环连通图，图中所有结点均参与，所有边的权重加起来最小。 算法 Prim算法 步骤：设N=(V,{E})是连通网， TE是N上最小生成树中边的集合 初始令U={u0},(u0V), TE=φ 在所有uU,vV-U的边(u,v)E中，找一条代价最小的边(u0,v0), 并保证不形成回路 将(u0,v0)并入集合TE，同时v0并入U 重复上述操作直至U=V为止，则T=(V,{TE})为N的最小生成树 总结：每次迭代加入所有连通边中权值最小的。 三角计数 定义：寻找无向图中的所有三角形 步骤 建立邻接表： 如果A-B &amp; A &lt; B，则将B加入A的邻接表 如果A-B &amp; B &lt; A，则将A加入B的邻接表 A&lt;B比较的是id 遍历每个节点，对于结点A，遍历A邻接表中的结点，如果邻接结点B,C两两之间存在边，则A、B、C三者之间存在三角形 社区发现 社区定义：同一社区内的节点与节点之间的连接很紧密，而社区与社区之间的连接比较稀疏。社区是一个子图 数学描述： 衡量标准：模块度 计算公式 常见算法 GN算法 思想：在一个网络之中，通过社区内部的边的最短路径相对较少，而通过社区之间的边的最短路径的数目则相对较多。从社区内部走大概率会走很多条边。 步骤 计算每一条边的边介数。边介数（betweenness）：网络中任意两个节点通过此边的最短路径的数目。 删除边介数最大的边 重复（1）（2），直到网络中的任一顶点作为一个社区为止。 缺陷 不知道最后会有多少个社区 在计算边介数的时候可能会有很对重复计算最短路径的情况，时间复杂度太高 GN算法不能判断算法终止位置 LPA算法（标签传播算法） 思路 自己是什么标签，由邻居决定。邻居中什么标签最多，则此结点是什么标签 步骤 为所有结点指定一个唯一的标签 逐轮刷新所有结点的标签，直到达到收敛要求位置。刷新规则： 对于某一个节点，考察其所有邻居节点的标签，并进行统计，将出现个数最多的那个标签赋给当前节点。当个数最多的标签不唯一时，随机选一个。 拓扑排序 定义 ：拓扑排序（Topological Sorting）是一个有向无环图（DAG, Directed Acyclic Graph）的所有顶点的线性序列。且该序列必须满足下面两个条件： 每个顶点出现且只出现一次 若存在一条从顶点 A 到顶点 B 的路径，那么在序列中顶点 A 出现在顶点 B 的前面 步骤 从 DAG 图中选择一个 没有前驱（即入度为0）的顶点并输出 从图中删除该顶点和所有以它为起点的有向边 重复 1 和 2 直到当前的 DAG 图为空或当前图中不存在无前驱的顶点为止。后一种情况说明有向图中必然存在环]]></content>
      <categories>
        <category>algorithm</category>
      </categories>
      <tags>
        <tag>graph</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ceph 部署文档]]></title>
    <url>%2F2018%2F04%2F17%2Fceph%E9%83%A8%E7%BD%B2%E6%96%87%E6%A1%A3%2F</url>
    <content type="text"><![CDATA[ceph 部署文档 1.配置所有节点创建ceph用户安装配置NTP systemctl enable ntp ubuntu 14.04不可用，感觉已经安装过了，因此跳过。 配置hosts文件172.16.1.93 object1172.16.1.94 object2172.16.1.95 object3172.16.1.66 object4172.16.1.92 controller 2. 配置ssh服务器修改ssh的配置文件 Host controller Hostname gd92 User cephuserHost object1 Hostname gd93 User cephuserHost object2 Hostname hw101 User cephuserHost object3 Hostname gd95 User cephuserHost object4 Hostname gd66 User cephuser 生成密钥并拷贝到4个osd节点上，无需拷贝到controller节点 3安装ceph主要参考链接：这些链接的操作大都一致，部分的顺序会有变化。 https://linux.cn/article-8182-1.html#4_10238 https://blog.csdn.net/styshoo/article/details/55471132 https://blog.csdn.net/styshoo/article/details/58572816 部署监控节点出现的问题ceph-deploy mon create-initial ceph-mon --cluster ceph --mkfs -i gd92 --keyring /var/lib/ceph/tmp/ceph-gd92.mon.keyring 问题：ceph.conf的配置文件中的public network=172.16.1.92/24 掩码前面多打了空格 修改后重新执行命令，并加上--overwrite-conf [info]Running command: ceph –cluster=ceph –admin-daemon /var/run/ceph/ceph-mon.controller.asok mon_status admin_socket: exception getting command descriptions: [Errno 2] No such file or directory 似乎是ceph -deploy 的问题，或者是ubuntu14.04的问题。教程是ubuntu16.04的 此问题非hostname 不对应 非conf 不同步导致。–overwrtie-conf 无作用。 解决办法：按照14.04方法重新安装ceph-deploy 部署osd节点出现的问题 使用ceph-deploy disk list ceph-osd1 ceph-osd2 ceph-osd3检查磁盘可用性时报错，使用ceph-deploy osd prepare ceph-osd1:/dev/sdb ceph-osd2:/dev/sdb ceph-osd3:/dev/sdb 在数据盘上面准备时也报错Running command: fdisk -l File “/usr/lib/python2.7/distpackages/ceph_deploy/util/decorators.py”, line 69, in newfunc问题：未知解决办法：将osd节点的数据目录放在指定目录，不用整个数据盘 最后部署后集群状况是health -ok，但是4osds，有3个osd up，一个osd down问题：down掉的节点磁盘有问题。解决办法：先卸载磁盘，重新格式化，挂载，重新激活osd节点 部署rgw节点出现的问题 显示rgw进程在工作，但是使用：http://controller:7480 显示拒绝连接。并且新建S3账号，测试时未返回正确结果。 问题：未知 尝试方法：重新部署 解决办法：重新部署后最开始将端口设置为80，发现可以创建s3账号，但是无法正确测试，显示创建bucket出错，查看rgw的log，发现端口被占用，无法打开，后面重新设置端口为7480问题解决，测试均正确。]]></content>
      <categories>
        <category>deploy</category>
      </categories>
      <tags>
        <tag>ceph</tag>
      </tags>
  </entry>
</search>
